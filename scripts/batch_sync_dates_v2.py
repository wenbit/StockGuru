#!/usr/bin/env python3
"""
æ”¹è¿›ç‰ˆæ‰¹é‡åŒæ­¥è„šæœ¬
é›†æˆé…ç½®ç®¡ç†ã€å¼‚å¸¸å¤„ç†ã€äº¤æ˜“æ—¥å†ç­‰æ”¹è¿›
"""

import os
import sys
import logging
import argparse
import time
import subprocess
from datetime import datetime, timedelta
from pathlib import Path
import psycopg2
from psycopg2 import pool

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from scripts.sync_config import config
from scripts.sync_exceptions import (
    SyncException, DatabaseConnectionError, ProcessTimeoutError,
    classify_exception, should_retry, get_retry_delay
)
from scripts.trading_calendar import TradingCalendar

# é…ç½®æ—¥å¿—
from logging.handlers import RotatingFileHandler

def setup_logging():
    """é…ç½®æ—¥å¿—ç³»ç»Ÿ"""
    # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
    log_dir = Path(config.LOG_FILE).parent
    log_dir.mkdir(parents=True, exist_ok=True)
    
    # åˆ›å»º logger
    logger = logging.getLogger()
    logger.setLevel(getattr(logging, config.LOG_LEVEL.upper()))
    
    # æ¸…é™¤ç°æœ‰å¤„ç†å™¨
    logger.handlers.clear()
    
    # æ–‡ä»¶å¤„ç†å™¨ï¼ˆå¸¦è½®è½¬ï¼‰
    file_handler = RotatingFileHandler(
        config.LOG_FILE,
        maxBytes=config.LOG_MAX_BYTES,
        backupCount=config.LOG_BACKUP_COUNT,
        encoding='utf-8'
    )
    file_formatter = logging.Formatter(
        '%(asctime)s [%(levelname)s] [%(name)s:%(lineno)d] %(message)s'
    )
    file_handler.setFormatter(file_formatter)
    
    # æ§åˆ¶å°å¤„ç†å™¨
    console_handler = logging.StreamHandler()
    console_formatter = logging.Formatter(
        '%(asctime)s [%(levelname)s] %(message)s'
    )
    console_handler.setFormatter(console_formatter)
    
    # æ·»åŠ å¤„ç†å™¨
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)
    
    return logger

logger = setup_logging()


class ImprovedBatchSyncManager:
    """æ”¹è¿›ç‰ˆæ‰¹é‡åŒæ­¥ç®¡ç†å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–"""
        logger.info("åˆå§‹åŒ–æ‰¹é‡åŒæ­¥ç®¡ç†å™¨...")
        
        # éªŒè¯é…ç½®
        try:
            config.validate()
            logger.info("é…ç½®éªŒè¯é€šè¿‡")
        except ValueError as e:
            logger.error(f"é…ç½®éªŒè¯å¤±è´¥: {e}")
            raise
        
        # åˆ›å»ºè¿æ¥æ± 
        try:
            self.db_pool = pool.ThreadedConnectionPool(
                minconn=config.DB_POOL_MIN_CONN,
                maxconn=config.DB_POOL_MAX_CONN,
                dsn=config.DATABASE_URL,
                connect_timeout=config.DB_CONNECT_TIMEOUT
            )
            logger.info(f"æ•°æ®åº“è¿æ¥æ± åˆ›å»ºæˆåŠŸ (min={config.DB_POOL_MIN_CONN}, max={config.DB_POOL_MAX_CONN})")
        except Exception as e:
            logger.error(f"æ•°æ®åº“è¿æ¥æ± åˆ›å»ºå¤±è´¥: {e}")
            raise DatabaseConnectionError(f"è¿æ¥æ± åˆ›å»ºå¤±è´¥: {e}")
        
        # åˆ›å»ºäº¤æ˜“æ—¥å†
        conn = self.get_connection()
        try:
            self.calendar = TradingCalendar(
                method=config.TRADING_DAY_METHOD,
                db_conn=conn
            )
            logger.info(f"äº¤æ˜“æ—¥å†åˆå§‹åŒ–å®Œæˆ (method={config.TRADING_DAY_METHOD})")
        finally:
            self.put_connection(conn)
        
        # æ€§èƒ½æŒ‡æ ‡
        self.metrics = {
            'total_dates': 0,
            'success_dates': 0,
            'failed_dates': 0,
            'skipped_dates': 0,
            'total_records': 0,
            'total_duration': 0,
            'start_time': None,
            'end_time': None
        }
    
    def get_connection(self):
        """ä»è¿æ¥æ± è·å–è¿æ¥"""
        try:
            return self.db_pool.getconn()
        except Exception as e:
            logger.error(f"è·å–æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
            raise DatabaseConnectionError(f"è·å–è¿æ¥å¤±è´¥: {e}")
    
    def put_connection(self, conn):
        """å½’è¿˜è¿æ¥åˆ°è¿æ¥æ± """
        try:
            self.db_pool.putconn(conn)
        except Exception as e:
            logger.warning(f"å½’è¿˜è¿æ¥å¤±è´¥: {e}")
    
    def health_check(self) -> bool:
        """å¥åº·æ£€æŸ¥"""
        if not config.ENABLE_HEALTH_CHECK:
            return True
        
        logger.info("æ‰§è¡Œå¥åº·æ£€æŸ¥...")
        
        # æ£€æŸ¥æ•°æ®åº“
        try:
            conn = self.get_connection()
            cursor = conn.cursor()
            cursor.execute("SELECT 1")
            cursor.fetchone()
            cursor.close()
            self.put_connection(conn)
            logger.info("âœ… æ•°æ®åº“å¥åº·æ£€æŸ¥é€šè¿‡")
        except Exception as e:
            logger.error(f"âŒ æ•°æ®åº“å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
            return False
        
        # æ£€æŸ¥ baostock
        try:
            import baostock as bs
            result = bs.login()
            if result.error_code == '0':
                bs.logout()
                logger.info("âœ… Baostock å¥åº·æ£€æŸ¥é€šè¿‡")
            else:
                logger.error(f"âŒ Baostock å¥åº·æ£€æŸ¥å¤±è´¥: {result.error_msg}")
                return False
        except Exception as e:
            logger.error(f"âŒ Baostock å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
            return False
        
        return True
    
    def is_trading_day(self, date_str: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºäº¤æ˜“æ—¥"""
        return self.calendar.is_trading_day(date_str)
    
    def get_sync_status(self, date_str: str) -> dict:
        """è·å–åŒæ­¥çŠ¶æ€"""
        conn = self.get_connection()
        try:
            cursor = conn.cursor()
            cursor.execute("""
                SELECT status, total_records, success_count, error_message
                FROM daily_sync_status
                WHERE sync_date = %s
            """, (date_str,))
            result = cursor.fetchone()
            cursor.close()
            
            if result:
                return {
                    'status': result[0],
                    'total_records': result[1],
                    'success_count': result[2],
                    'error_message': result[3]
                }
            return None
        finally:
            self.put_connection(conn)
    
    def update_sync_status(self, date_str: str, status: str, total_records: int,
                          success_count: int, start_time: str, end_time: str,
                          duration_seconds: int, error_message: str = None):
        """æ›´æ–°åŒæ­¥çŠ¶æ€"""
        conn = self.get_connection()
        try:
            cursor = conn.cursor()
            
            # å°è¯•æ›´æ–°
            cursor.execute("""
                UPDATE daily_sync_status
                SET
                    status = %s,
                    total_records = %s,
                    success_count = %s,
                    failed_count = %s,
                    start_time = %s,
                    end_time = %s,
                    duration_seconds = %s,
                    error_message = %s,
                    remarks = %s,
                    updated_at = NOW()
                WHERE sync_date = %s
                RETURNING sync_date
            """, (
                status, total_records, success_count,
                total_records - success_count,
                start_time, end_time, duration_seconds, error_message,
                f'æ‰¹é‡åŒæ­¥ï¼Œå…±{total_records}æ¡ï¼ŒæˆåŠŸ{success_count}æ¡',
                date_str
            ))
            
            result = cursor.fetchone()
            
            if not result:
                # æ’å…¥æ–°è®°å½•
                cursor.execute("""
                    INSERT INTO daily_sync_status (
                        sync_date, status, total_records, success_count, failed_count,
                        start_time, end_time, duration_seconds, error_message, remarks,
                        created_at, updated_at
                    ) VALUES (
                        %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, NOW(), NOW()
                    )
                """, (
                    date_str, status, total_records, success_count,
                    total_records - success_count,
                    start_time, end_time, duration_seconds, error_message,
                    f'æ‰¹é‡åŒæ­¥ï¼Œå…±{total_records}æ¡ï¼ŒæˆåŠŸ{success_count}æ¡'
                ))
            
            conn.commit()
            cursor.close()
            logger.info(f"âœ… {date_str} çŠ¶æ€å·²æ›´æ–°: {status}")
        except Exception as e:
            conn.rollback()
            logger.error(f"âŒ æ›´æ–°çŠ¶æ€å¤±è´¥: {e}")
            raise
        finally:
            self.put_connection(conn)
    
    def monitor_sync_process(self, process, date_str: str) -> bool:
        """ç›‘æ§åŒæ­¥è¿›ç¨‹"""
        error_count = 0
        last_error_time = None
        start_time = time.time()
        
        while True:
            # æ£€æŸ¥è¶…æ—¶
            if time.time() - start_time > config.SYNC_TIMEOUT_SECONDS:
                logger.error(f"âŒ {date_str} åŒæ­¥è¶…æ—¶ ({config.SYNC_TIMEOUT_SECONDS}ç§’)")
                process.terminate()
                time.sleep(2)
                if process.poll() is None:
                    process.kill()
                raise ProcessTimeoutError(f"åŒæ­¥è¶…æ—¶: {config.SYNC_TIMEOUT_SECONDS}ç§’")
            
            # è¯»å–è¾“å‡º
            line = process.stdout.readline()
            if not line and process.poll() is not None:
                break
            
            if line:
                line = line.strip()
                print(line)  # å®æ—¶è¾“å‡º
                
                # æ£€æµ‹é”™è¯¯ï¼ˆæ’é™¤è¿›åº¦æ—¥å¿—ä¸­çš„æ­£å¸¸ä¿¡æ¯ï¼‰
                if ('âŒ' in line or 'ERROR' in line or 'å¤±è´¥' in line) and 'é¢„è®¡å‰©ä½™' not in line and 'è¿›åº¦:' not in line:
                    current_time = time.time()
                    
                    # é‡ç½®è®¡æ•°å™¨ï¼ˆè¶…è¿‡æ—¶é—´çª—å£ï¼‰
                    if last_error_time and (current_time - last_error_time) > config.ERROR_WINDOW_SECONDS:
                        error_count = 0
                    
                    error_count += 1
                    last_error_time = current_time
                    
                    logger.warning(f"âš ï¸  æ£€æµ‹åˆ°é”™è¯¯ ({error_count}/{config.MAX_ERROR_COUNT})")
                    
                    # è¶…è¿‡é˜ˆå€¼ï¼Œç»ˆæ­¢è¿›ç¨‹
                    if error_count >= config.MAX_ERROR_COUNT:
                        logger.error(f"âŒ {date_str} æŒç»­é”™è¯¯ ({error_count}æ¬¡)ï¼Œç»ˆæ­¢åŒæ­¥")
                        process.terminate()
                        time.sleep(2)
                        if process.poll() is None:
                            process.kill()
                        return False
        
        return process.returncode == 0
    
    def is_sync_process_running(self, date_str: str) -> bool:
        """æ£€æŸ¥æŒ‡å®šæ—¥æœŸçš„åŒæ­¥è¿›ç¨‹æ˜¯å¦æ­£åœ¨è¿è¡Œ"""
        try:
            import subprocess
            # æŸ¥æ‰¾åŒ…å«è¯¥æ—¥æœŸçš„åŒæ­¥è¿›ç¨‹
            result = subprocess.run(
                ['ps', 'aux'],
                capture_output=True,
                text=True
            )
            
            # æ£€æŸ¥æ˜¯å¦æœ‰è¯¥æ—¥æœŸçš„åŒæ­¥è¿›ç¨‹
            for line in result.stdout.split('\n'):
                if 'test_copy_sync.py' in line and date_str in line and 'grep' not in line:
                    logger.warning(f"âš ï¸  æ£€æµ‹åˆ° {date_str} çš„åŒæ­¥è¿›ç¨‹æ­£åœ¨è¿è¡Œ")
                    # æå–PID
                    parts = line.split()
                    if len(parts) > 1:
                        pid = parts[1]
                        logger.warning(f"   è¿›ç¨‹PID: {pid}")
                    return True
            return False
        except Exception as e:
            logger.warning(f"æ£€æŸ¥è¿›ç¨‹çŠ¶æ€å¤±è´¥: {e}")
            return False
    
    def sync_date_with_retry(self, date_str: str) -> bool:
        """åŒæ­¥å•ä¸ªæ—¥æœŸï¼ˆæ”¯æŒé‡è¯•ï¼‰"""
        logger.info(f"\n{'='*80}")
        logger.info(f"å¼€å§‹åŒæ­¥: {date_str}")
        logger.info(f"{'='*80}\n")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰åŒæ­¥è¿›ç¨‹æ­£åœ¨è¿è¡Œ
        if self.is_sync_process_running(date_str):
            logger.warning(f"âš ï¸  {date_str} å·²æœ‰åŒæ­¥è¿›ç¨‹åœ¨è¿è¡Œï¼Œè·³è¿‡")
            self.metrics['skipped_dates'] += 1
            return True
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºäº¤æ˜“æ—¥
        if not self.is_trading_day(date_str):
            logger.info(f"âš ï¸  {date_str} éäº¤æ˜“æ—¥ï¼Œè·³è¿‡")
            # å†™å…¥æ•°æ®åº“è®°å½•
            start_time = datetime.now()
            start_time_str = start_time.strftime('%Y-%m-%d %H:%M:%S')
            end_time_str = start_time_str
            self.update_sync_status(
                date_str, 'skipped', 0, 0,
                start_time_str, end_time_str, 0,
                error_message='éäº¤æ˜“æ—¥ï¼ˆå‘¨æœ«/èŠ‚å‡æ—¥ï¼‰'
            )
            self.metrics['skipped_dates'] += 1
            return True
        
        # æ£€æŸ¥æ˜¯å¦å·²åŒæ­¥
        sync_status = self.get_sync_status(date_str)
        if sync_status and sync_status['status'] == 'success':
            logger.info(f"âœ… {date_str} å·²åŒæ­¥å®Œæˆ ({sync_status['success_count']} æ¡)ï¼Œè·³è¿‡")
            self.metrics['skipped_dates'] += 1
            return True
        
        # é‡è¯•å¾ªç¯
        for attempt in range(1, config.MAX_RETRIES_PER_DATE + 1):
            logger.info(f"\nğŸ”„ å°è¯• {attempt}/{config.MAX_RETRIES_PER_DATE}")
            
            start_time = datetime.now()
            start_time_str = start_time.strftime('%Y-%m-%d %H:%M:%S')
            
            try:
                # å¯åŠ¨åŒæ­¥è¿›ç¨‹
                process = subprocess.Popen(
                    ['python3', 'scripts/test_copy_sync.py', '--all', '--date', date_str],
                    cwd=project_root,
                    stdout=subprocess.PIPE,
                    stderr=subprocess.STDOUT,
                    text=True,
                    bufsize=1
                )
                
                # ç›‘æ§è¿›ç¨‹
                success = self.monitor_sync_process(process, date_str)
                
                # è®°å½•ç»“æŸæ—¶é—´
                end_time = datetime.now()
                end_time_str = end_time.strftime('%Y-%m-%d %H:%M:%S')
                duration_seconds = int((end_time - start_time).total_seconds())
                
                if success:
                    # æŸ¥è¯¢å®é™…åŒæ­¥æ•°é‡
                    conn = self.get_connection()
                    try:
                        cursor = conn.cursor()
                        cursor.execute("""
                            SELECT COUNT(*) 
                            FROM daily_stock_data 
                            WHERE trade_date = %s
                        """, (date_str,))
                        success_count = cursor.fetchone()[0]
                        cursor.close()
                    finally:
                        self.put_connection(conn)
                    
                    if success_count > 0:
                        # æœ‰æ•°æ®ï¼šæ­£å¸¸äº¤æ˜“æ—¥
                        self.update_sync_status(
                            date_str, 'success', success_count, success_count,
                            start_time_str, end_time_str, duration_seconds
                        )
                        
                        # æ›´æ–°æŒ‡æ ‡
                        self.metrics['success_dates'] += 1
                        self.metrics['total_records'] += success_count
                        self.metrics['total_duration'] += duration_seconds
                        
                        logger.info(f"\nâœ… {date_str} åŒæ­¥æˆåŠŸ")
                        logger.info(f"   è®°å½•æ•°: {success_count:,}")
                        logger.info(f"   è€—æ—¶: {duration_seconds}ç§’ ({duration_seconds/60:.1f}åˆ†é’Ÿ)\n")
                        return True
                    else:
                        # æ— æ•°æ®ï¼šéäº¤æ˜“æ—¥ï¼ˆèŠ‚å‡æ—¥/å‘¨æœ«ï¼‰
                        self.update_sync_status(
                            date_str, 'skipped', 0, 0,
                            start_time_str, end_time_str, duration_seconds,
                            error_message='éäº¤æ˜“æ—¥ï¼Œæ— æ•°æ®'
                        )
                        
                        self.metrics['skipped_dates'] += 1
                        
                        logger.info(f"\nâš ï¸  {date_str} éäº¤æ˜“æ—¥ï¼ˆ0æ¡æ•°æ®ï¼‰")
                        logger.info(f"   è€—æ—¶: {duration_seconds}ç§’\n")
                        return True
                
                # å¤±è´¥å¤„ç†
                if attempt < config.MAX_RETRIES_PER_DATE:
                    retry_delay = config.RETRY_WAIT_SECONDS
                    logger.warning(f"âš ï¸  å°è¯• {attempt} å¤±è´¥ï¼Œç­‰å¾…{retry_delay}ç§’åé‡è¯•...")
                    time.sleep(retry_delay)
                else:
                    # æœ€åä¸€æ¬¡å¤±è´¥
                    error_message = f"é‡è¯•{config.MAX_RETRIES_PER_DATE}æ¬¡åä»ç„¶å¤±è´¥"
                    self.update_sync_status(
                        date_str, 'failed', 0, 0,
                        start_time_str, end_time_str, duration_seconds, error_message
                    )
                    self.metrics['failed_dates'] += 1
                    logger.error(f"\nâŒ {date_str} åŒæ­¥å¤±è´¥ï¼ˆå·²é‡è¯•{config.MAX_RETRIES_PER_DATE}æ¬¡ï¼‰\n")
                    return False
            
            except SyncException as e:
                # è‡ªå®šä¹‰å¼‚å¸¸
                logger.error(f"âŒ å°è¯• {attempt} å¼‚å¸¸: {e}")
                
                if not should_retry(e):
                    logger.error(f"âŒ å¼‚å¸¸ä¸å¯é‡è¯•ï¼Œæ”¾å¼ƒ")
                    end_time = datetime.now()
                    end_time_str = end_time.strftime('%Y-%m-%d %H:%M:%S')
                    duration_seconds = int((end_time - start_time).total_seconds())
                    self.update_sync_status(
                        date_str, 'failed', 0, 0,
                        start_time_str, end_time_str, duration_seconds, str(e)
                    )
                    self.metrics['failed_dates'] += 1
                    return False
                
                if attempt < config.MAX_RETRIES_PER_DATE:
                    retry_delay = get_retry_delay(e, attempt, config.RETRY_WAIT_SECONDS)
                    logger.warning(f"âš ï¸  ç­‰å¾…{retry_delay}ç§’åé‡è¯•...")
                    time.sleep(retry_delay)
            
            except Exception as e:
                # æœªåˆ†ç±»å¼‚å¸¸
                classified_exc = classify_exception(e)
                logger.error(f"âŒ å°è¯• {attempt} å¼‚å¸¸: {classified_exc}")
                
                if attempt < config.MAX_RETRIES_PER_DATE:
                    retry_delay = get_retry_delay(classified_exc, attempt, config.RETRY_WAIT_SECONDS)
                    logger.warning(f"âš ï¸  ç­‰å¾…{retry_delay}ç§’åé‡è¯•...")
                    time.sleep(retry_delay)
        
        return False
    
    def batch_sync(self, dates: list):
        """æ‰¹é‡åŒæ­¥"""
        logger.info(f"\n{'='*80}")
        logger.info(f"æ‰¹é‡åŒæ­¥ä»»åŠ¡å¼€å§‹")
        logger.info(f"å¾…åŒæ­¥æ—¥æœŸ: {len(dates)} ä¸ª")
        logger.info(f"{'='*80}\n")
        
        # å¥åº·æ£€æŸ¥
        if not self.health_check():
            logger.error("âŒ å¥åº·æ£€æŸ¥å¤±è´¥ï¼Œç»ˆæ­¢åŒæ­¥")
            return
        
        # åˆå§‹åŒ–æŒ‡æ ‡
        self.metrics['total_dates'] = len(dates)
        self.metrics['start_time'] = datetime.now()
        
        failed_dates = []
        
        # éå†æ—¥æœŸ
        for idx, date_str in enumerate(dates, 1):
            logger.info(f"\nğŸ“… å¤„ç†æ—¥æœŸ {idx}/{len(dates)}: {date_str}")
            
            try:
                result = self.sync_date_with_retry(date_str)
                if not result:
                    failed_dates.append(date_str)
                    logger.warning(f"âš ï¸  {date_str} å¤±è´¥ï¼Œç»§ç»­ä¸‹ä¸€ä¸ª")
            except Exception as e:
                failed_dates.append(date_str)
                logger.error(f"âŒ {date_str} å¼‚å¸¸: {e}")
                logger.warning(f"âš ï¸  è·³è¿‡ {date_str}ï¼Œç»§ç»­ä¸‹ä¸€ä¸ª")
            
            # æ—¥æœŸé—´éš”
            if idx < len(dates):
                time.sleep(config.DATE_INTERVAL_SECONDS)
        
        # è®°å½•ç»“æŸæ—¶é—´
        self.metrics['end_time'] = datetime.now()
        
        # è¾“å‡ºç»Ÿè®¡
        self.print_summary(failed_dates)
    
    def print_summary(self, failed_dates: list):
        """æ‰“å°ç»Ÿè®¡æ‘˜è¦"""
        logger.info(f"\n{'='*80}")
        logger.info(f"æ‰¹é‡åŒæ­¥ä»»åŠ¡å®Œæˆ")
        logger.info(f"{'='*80}")
        logger.info(f"âœ… æˆåŠŸ: {self.metrics['success_dates']}")
        logger.info(f"âŒ å¤±è´¥: {self.metrics['failed_dates']}")
        logger.info(f"â­ï¸  è·³è¿‡: {self.metrics['skipped_dates']}")
        logger.info(f"ğŸ“Š æ€»è®°å½•: {self.metrics['total_records']:,}")
        
        if self.metrics['start_time'] and self.metrics['end_time']:
            total_time = (self.metrics['end_time'] - self.metrics['start_time']).total_seconds()
            logger.info(f"â±ï¸  æ€»è€—æ—¶: {total_time:.0f}ç§’ ({total_time/60:.1f}åˆ†é’Ÿ)")
        
        if self.metrics['success_dates'] > 0:
            avg_duration = self.metrics['total_duration'] / self.metrics['success_dates']
            avg_records = self.metrics['total_records'] / self.metrics['success_dates']
            logger.info(f"ğŸ“ˆ å¹³å‡è€—æ—¶: {avg_duration:.0f}ç§’/æ—¥")
            logger.info(f"ğŸ“ˆ å¹³å‡è®°å½•: {avg_records:.0f}æ¡/æ—¥")
        
        if failed_dates:
            logger.info(f"å¤±è´¥æ—¥æœŸ: {', '.join(failed_dates)}")
        
        logger.info(f"{'='*80}\n")
    
    def close(self):
        """å…³é—­èµ„æº"""
        if hasattr(self, 'db_pool'):
            self.db_pool.closeall()
            logger.info("æ•°æ®åº“è¿æ¥æ± å·²å…³é—­")


def generate_date_range(start_date: str, end_date: str) -> list:
    """ç”Ÿæˆæ—¥æœŸèŒƒå›´"""
    start = datetime.strptime(start_date, '%Y-%m-%d')
    end = datetime.strptime(end_date, '%Y-%m-%d')
    
    dates = []
    current = start
    while current <= end:
        dates.append(current.strftime('%Y-%m-%d'))
        current += timedelta(days=1)
    
    return dates


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='æ”¹è¿›ç‰ˆæ‰¹é‡åŒæ­¥è„šæœ¬')
    parser.add_argument('--dates', nargs='+', help='æŒ‡å®šæ—¥æœŸåˆ—è¡¨')
    parser.add_argument('--start', help='èµ·å§‹æ—¥æœŸ')
    parser.add_argument('--end', help='ç»“æŸæ—¥æœŸ')
    parser.add_argument('--config', action='store_true', help='æ˜¾ç¤ºé…ç½®')
    
    args = parser.parse_args()
    
    # æ˜¾ç¤ºé…ç½®
    if args.config:
        config.print_config()
        return
    
    # ç¡®å®šæ—¥æœŸåˆ—è¡¨
    dates = []
    if args.dates:
        dates = args.dates
    elif args.start and args.end:
        dates = generate_date_range(args.start, args.end)
    else:
        parser.print_help()
        sys.exit(1)
    
    # æ‰§è¡ŒåŒæ­¥
    manager = ImprovedBatchSyncManager()
    try:
        manager.batch_sync(dates)
    except KeyboardInterrupt:
        logger.warning("\nâš ï¸  ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        logger.error(f"\nâŒ æ‰¹é‡åŒæ­¥å¼‚å¸¸: {e}", exc_info=True)
    finally:
        manager.close()


if __name__ == '__main__':
    main()
