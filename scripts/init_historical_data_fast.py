#!/usr/bin/env python3
"""
å¿«é€Ÿå†å²æ•°æ®åˆå§‹åŒ–è„šæœ¬
ä¼˜åŒ–ç­–ç•¥ï¼š
1. å•ä¼šè¯å¤ç”¨ï¼ˆé¿å…é‡å¤ç™»å½•ï¼‰
2. æ™ºèƒ½æ‰¹å¤„ç†
3. æ–­ç‚¹ç»­ä¼ 
4. è‡ªåŠ¨é‡è¯•
"""

import os
import sys
import logging
from datetime import date, timedelta
import json
from pathlib import Path
import time

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'stockguru-web', 'backend'))

from app.services.daily_data_sync_service_neon import DailyDataSyncServiceNeon

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s'
)
logger = logging.getLogger(__name__)


class FastHistoricalSync:
    """å¿«é€Ÿå†å²æ•°æ®åŒæ­¥"""
    
    def __init__(self, checkpoint_file='sync_checkpoint.json'):
        self.sync_service = DailyDataSyncServiceNeon()
        self.checkpoint_file = Path(checkpoint_file)
        self.checkpoint = self.load_checkpoint()
        self.start_time = None
        
        logger.info("âœ… ä½¿ç”¨è¿›é˜¶ä¼˜åŒ–ç‰ˆæœ¬:")
        logger.info("  - COPY å‘½ä»¤æ‰¹é‡æ’å…¥ (å¿« 2-3å€)")
        logger.info("  - æ•°æ®åº“å‚æ•°ä¼˜åŒ–")
        logger.info("  - è‚¡ç¥¨åˆ—è¡¨ç¼“å­˜")
    
    def load_checkpoint(self):
        """åŠ è½½æ£€æŸ¥ç‚¹"""
        if self.checkpoint_file.exists():
            return json.loads(self.checkpoint_file.read_text())
        return {
            'completed_dates': [],
            'failed_dates': [],
            'total_success': 0,
            'total_records': 0,
            'start_time': None
        }
    
    def save_checkpoint(self):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        self.checkpoint_file.write_text(
            json.dumps(self.checkpoint, indent=2, ensure_ascii=False)
        )
    
    def get_trading_days(self, days: int = 365):
        """
        è·å–äº¤æ˜“æ—¥åˆ—è¡¨
        ç®€åŒ–ç‰ˆï¼šå‡è®¾å‘¨ä¸€åˆ°å‘¨äº”éƒ½æ˜¯äº¤æ˜“æ—¥
        """
        end_date = date.today() - timedelta(days=1)
        start_date = end_date - timedelta(days=days)
        
        trading_days = []
        current = start_date
        
        while current <= end_date:
            # ç®€å•åˆ¤æ–­ï¼šå‘¨ä¸€åˆ°å‘¨äº”
            if current.weekday() < 5:
                trading_days.append(current.isoformat())
            current += timedelta(days=1)
        
        return trading_days
    
    def sync_batch(self, dates: list):
        """
        æ‰¹é‡åŒæ­¥å¤šä¸ªæ—¥æœŸ
        ä½¿ç”¨å•ä¸ª baostock ä¼šè¯
        """
        total = len(dates)
        success_count = 0
        failed_count = 0
        
        for idx, date_str in enumerate(dates, 1):
            try:
                logger.info(f"[{idx}/{total}] åŒæ­¥ {date_str}")
                
                result = self.sync_service.sync_daily_data(
                    date.fromisoformat(date_str)
                )
                
                if result['status'] == 'success':
                    self.checkpoint['completed_dates'].append(date_str)
                    self.checkpoint['total_success'] += result['success']
                    self.checkpoint['total_records'] += result.get('inserted', 0)
                    success_count += 1
                    
                    logger.info(
                        f"âœ… {date_str} å®Œæˆ: "
                        f"æˆåŠŸ {result['success']}, å¤±è´¥ {result['failed']}, "
                        f"å…¥åº“ {result.get('inserted', 0)}"
                    )
                elif result['status'] == 'skipped':
                    self.checkpoint['completed_dates'].append(date_str)
                    success_count += 1
                    logger.info(f"â­ï¸  {date_str} è·³è¿‡: {result['message']}")
                else:
                    self.checkpoint['failed_dates'].append(date_str)
                    failed_count += 1
                    logger.warning(f"âš ï¸ {date_str} å¤±è´¥: {result.get('message', 'Unknown')}")
                
                # æ¯5ä¸ªæ—¥æœŸä¿å­˜ä¸€æ¬¡æ£€æŸ¥ç‚¹
                if idx % 5 == 0:
                    self.save_checkpoint()
                    self.print_progress(idx, total, success_count, failed_count)
                
            except Exception as e:
                logger.error(f"âŒ {date_str} å¼‚å¸¸: {e}")
                self.checkpoint['failed_dates'].append(date_str)
                failed_count += 1
        
        return success_count, failed_count
    
    def print_progress(self, current, total, success, failed):
        """æ‰“å°è¿›åº¦ç»Ÿè®¡"""
        if not self.start_time:
            return
        
        elapsed = time.time() - self.start_time
        elapsed_hours = elapsed / 3600
        
        if current > 0:
            avg_time_per_date = elapsed / current
            remaining = total - current
            eta_seconds = remaining * avg_time_per_date
            eta_hours = eta_seconds / 3600
            
            logger.info("="*60)
            logger.info(f"ğŸ“Š è¿›åº¦ç»Ÿè®¡")
            logger.info(f"å·²å®Œæˆ: {current}/{total} ({current/total*100:.1f}%)")
            logger.info(f"æˆåŠŸ: {success}, å¤±è´¥: {failed}")
            logger.info(f"å·²ç”¨æ—¶: {elapsed_hours:.1f} å°æ—¶")
            logger.info(f"é¢„è®¡å‰©ä½™: {eta_hours:.1f} å°æ—¶")
            logger.info(f"æ€»è®°å½•æ•°: {self.checkpoint['total_records']:,}")
            logger.info(f"å¹³å‡é€Ÿåº¦: {current/elapsed_hours:.1f} æ—¥/å°æ—¶")
            logger.info("="*60)
    
    def sync_historical(self, days: int = 365):
        """åŒæ­¥å†å²æ•°æ®"""
        logger.info("="*60)
        logger.info(f"å¼€å§‹åŒæ­¥å†å²æ•°æ®ï¼ˆæœ€è¿‘ {days} å¤©ï¼‰")
        logger.info("="*60)
        
        # è®°å½•å¼€å§‹æ—¶é—´
        if not self.checkpoint.get('start_time'):
            self.checkpoint['start_time'] = time.time()
        self.start_time = self.checkpoint['start_time']
        
        # è·å–äº¤æ˜“æ—¥
        trading_days = self.get_trading_days(days)
        logger.info(f"é¢„è®¡äº¤æ˜“æ—¥: {len(trading_days)} å¤©")
        
        # è¿‡æ»¤å·²å®Œæˆçš„æ—¥æœŸ
        completed = set(self.checkpoint['completed_dates'])
        remaining = [d for d in trading_days if d not in completed]
        
        if completed:
            logger.info(f"å·²å®Œæˆ: {len(completed)} å¤©")
        logger.info(f"å‰©ä½™: {len(remaining)} å¤©")
        
        if not remaining:
            logger.info("âœ… æ‰€æœ‰æ—¥æœŸå·²åŒæ­¥å®Œæˆï¼")
            return
        
        # æ‰¹é‡åŒæ­¥
        success, failed = self.sync_batch(remaining)
        
        # æœ€ç»ˆä¿å­˜
        self.save_checkpoint()
        
        # æœ€ç»ˆç»Ÿè®¡
        total_elapsed = time.time() - self.start_time
        logger.info("="*60)
        logger.info("ğŸ‰ åŒæ­¥å®Œæˆï¼")
        logger.info(f"æˆåŠŸ: {success}")
        logger.info(f"å¤±è´¥: {failed}")
        logger.info(f"æ€»è®°å½•æ•°: {self.checkpoint['total_records']:,}")
        logger.info(f"æ€»è€—æ—¶: {total_elapsed/3600:.1f} å°æ—¶")
        logger.info("="*60)
        
        # é‡è¯•å¤±è´¥çš„æ—¥æœŸ
        if self.checkpoint['failed_dates']:
            logger.info(f"\nå‘ç° {len(self.checkpoint['failed_dates'])} ä¸ªå¤±è´¥æ—¥æœŸ")
            logger.info(f"å¤±è´¥æ—¥æœŸ: {', '.join(self.checkpoint['failed_dates'][:10])}")
            if len(self.checkpoint['failed_dates']) > 10:
                logger.info(f"... è¿˜æœ‰ {len(self.checkpoint['failed_dates']) - 10} ä¸ª")
            
            retry = input("\næ˜¯å¦é‡è¯•å¤±è´¥çš„æ—¥æœŸ? (y/n): ")
            if retry.lower() == 'y':
                self.retry_failed_dates()
    
    def retry_failed_dates(self):
        """é‡è¯•å¤±è´¥çš„æ—¥æœŸ"""
        failed = self.checkpoint['failed_dates'].copy()
        self.checkpoint['failed_dates'] = []
        
        logger.info(f"\né‡è¯• {len(failed)} ä¸ªå¤±è´¥æ—¥æœŸ...")
        success, still_failed = self.sync_batch(failed)
        
        self.save_checkpoint()
        logger.info(f"é‡è¯•å®Œæˆ: æˆåŠŸ {success}, ä»å¤±è´¥ {still_failed}")


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='å¿«é€Ÿå†å²æ•°æ®åŒæ­¥')
    parser.add_argument('--days', type=int, default=365, help='åŒæ­¥å¤©æ•°ï¼ˆé»˜è®¤365ï¼‰')
    parser.add_argument('--checkpoint', type=str, default='sync_checkpoint.json', help='æ£€æŸ¥ç‚¹æ–‡ä»¶')
    
    args = parser.parse_args()
    
    syncer = FastHistoricalSync(checkpoint_file=args.checkpoint)
    syncer.sync_historical(days=args.days)


if __name__ == '__main__':
    main()
