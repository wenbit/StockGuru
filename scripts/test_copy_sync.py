#!/usr/bin/env python3
"""
æµ‹è¯• PostgreSQL COPY æ–¹æ¡ˆæ€§èƒ½
åŒæ­¥å°‘é‡è‚¡ç¥¨æ•°æ®æ¥éªŒè¯é€Ÿåº¦æå‡

ä½¿ç”¨æ–¹æ³•:
    # æ–¹å¼1: ä½¿ç”¨ DATABASE_URL (æ¨è)
    export DATABASE_URL='postgresql://user:password@host:port/database?sslmode=require'
    python scripts/test_copy_sync.py --stocks 50 --date 2025-10-09
    
    # æ–¹å¼2: ä½¿ç”¨ç‹¬ç«‹ç¯å¢ƒå˜é‡
    export SUPABASE_DB_PASSWORD='your_password'
    python scripts/test_copy_sync.py --stocks 50 --date 2025-10-09
"""

import os
import sys
import logging
import argparse
import time
from datetime import date, datetime
from typing import List, Dict, Optional
import pandas as pd
import numpy as np
import baostock as bs
import psycopg2
from io import StringIO

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s'
)
logger = logging.getLogger(__name__)


class CopySyncTester:
    """COPY æ–¹æ¡ˆæ€§èƒ½æµ‹è¯•å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–"""
        # ä¼˜å…ˆä½¿ç”¨ DATABASE_URL
        database_url = os.getenv('DATABASE_URL') or os.getenv('NEON_DATABASE_URL')
        
        if database_url:
            # ä½¿ç”¨ DATABASE_URL è¿æ¥
            logger.info("ä½¿ç”¨ DATABASE_URL è¿æ¥æ•°æ®åº“")
            self.conn = psycopg2.connect(database_url)
            logger.info("æ•°æ®åº“è¿æ¥æˆåŠŸ (DATABASE_URL)")
        else:
            # å›é€€åˆ°ç‹¬ç«‹ç¯å¢ƒå˜é‡
            self.db_host = os.getenv('SUPABASE_DB_HOST', 'db.mislyhozlviaedinpnfa.supabase.co')
            self.db_password = os.getenv('SUPABASE_DB_PASSWORD')
            self.db_port = int(os.getenv('SUPABASE_DB_PORT', '6543'))
            
            if not self.db_password:
                raise ValueError(
                    "è¯·è®¾ç½®ç¯å¢ƒå˜é‡: DATABASE_URL æˆ– SUPABASE_DB_PASSWORD\n"
                    "ç¤ºä¾‹: export DATABASE_URL='postgresql://user:password@host:port/database?sslmode=require'"
                )
            
            # è¿æ¥æ•°æ®åº“
            self.conn = psycopg2.connect(
                host=self.db_host,
                port=self.db_port,
                database='postgres',
                user='postgres',
                password=self.db_password,
                sslmode='require'
            )
            logger.info(f"æ•°æ®åº“è¿æ¥æˆåŠŸ: {self.db_host}:{self.db_port}")
        
        # ç™»å½• baostock
        bs.login()
        logger.info("baostock ç™»å½•æˆåŠŸ")
        
        # ä¿å­˜è¿æ¥å‚æ•°ä»¥ä¾¿é‡è¿
        self.database_url = database_url
        self.db_params = {
            'host': self.db_host if not database_url else None,
            'port': self.db_port if not database_url else None,
            'database': 'postgres' if not database_url else None,
            'user': 'postgres' if not database_url else None,
            'password': self.db_password if not database_url else None,
            'sslmode': 'require' if not database_url else None
        }
    
    def _reconnect(self):
        """é‡æ–°è¿æ¥æ•°æ®åº“"""
        try:
            if self.conn and not self.conn.closed:
                self.conn.close()
        except:
            pass
        
        if self.database_url:
            self.conn = psycopg2.connect(self.database_url)
            logger.info("æ•°æ®åº“é‡æ–°è¿æ¥æˆåŠŸ (DATABASE_URL)")
        else:
            self.conn = psycopg2.connect(**{k: v for k, v in self.db_params.items() if v is not None})
            logger.info(f"æ•°æ®åº“é‡æ–°è¿æ¥æˆåŠŸ: {self.db_host}:{self.db_port}")
    
    def get_stocks(self, limit: int = None) -> List[Dict[str, str]]:
        """è·å–æŒ‡å®šæ•°é‡çš„è‚¡ç¥¨"""
        if limit:
            logger.info(f"è·å–å‰ {limit} åªè‚¡ç¥¨...")
        else:
            logger.info(f"è·å–æ‰€æœ‰Aè‚¡è‚¡ç¥¨...")
        
        # åŠ¨æ€è·å–æœ€æ–°è‚¡ç¥¨åˆ—è¡¨ï¼ˆè‡ªåŠ¨åŒ…å«æ–°è‚¡ã€æ’é™¤é€€å¸‚è‚¡ï¼‰
        from datetime import date
        today = date.today().strftime('%Y-%m-%d')
        rs = bs.query_all_stock(day=today)
        logger.info(f"æŸ¥è¯¢æ—¥æœŸ: {today}")
        
        stocks = []
        while (rs.error_code == '0') & rs.next():
            row = rs.get_row_data()
            # fields: ['code', 'tradeStatus', 'code_name']
            # row[0] = code (å¦‚ 'sh.600000')
            # row[1] = tradeStatus
            # row[2] = code_name
            
            code = row[0]
            name = row[2]
            
            # åªè·å– Aè‚¡ç¥¨ï¼ˆ6ä½æ•°å­—ä»£ç ï¼‰
            # æ’é™¤æŒ‡æ•°ï¼ˆå¦‚ sh.000001ï¼‰å’Œå…¶ä»–éè‚¡ç¥¨ä»£ç 
            if code and '.' in code:
                stock_code = code.split('.')[1]
                # Aè‚¡ä»£ç è§„åˆ™ï¼š
                # æ²ªå¸‚ä¸»æ¿: 600xxx, 601xxx, 603xxx, 605xxx
                # æ²ªå¸‚ç§‘åˆ›æ¿: 688xxx
                # æ·±å¸‚ä¸»æ¿: 000xxx, 001xxx
                # æ·±å¸‚ä¸­å°æ¿: 002xxx, 003xxx, 004xxx
                # æ·±å¸‚åˆ›ä¸šæ¿: 300xxx, 301xxx
                # åŒ—äº¤æ‰€: 8xxxxx, 43xxxx
                if (stock_code.startswith('600') or stock_code.startswith('601') or 
                    stock_code.startswith('603') or stock_code.startswith('605') or
                    stock_code.startswith('688') or  # ç§‘åˆ›æ¿
                    stock_code.startswith('000') or stock_code.startswith('001') or
                    stock_code.startswith('002') or stock_code.startswith('003') or stock_code.startswith('004') or
                    stock_code.startswith('300') or stock_code.startswith('301') or  # åˆ›ä¸šæ¿
                    stock_code.startswith('8') or stock_code.startswith('43')):  # åŒ—äº¤æ‰€
                    stocks.append({
                        'code': stock_code,
                        'full_code': code,
                        'name': name
                    })
                    if limit and len(stocks) >= limit:
                        break
        
        logger.info(f"è·å–åˆ° {len(stocks)} åªè‚¡ç¥¨")
        return stocks
    
    def fetch_stock_data(self, stock: Dict, date_str: str) -> Optional[pd.DataFrame]:
        """è·å–å•åªè‚¡ç¥¨æ•°æ®"""
        try:
            rs = bs.query_history_k_data_plus(
                stock['full_code'],
                "date,code,open,high,low,close,volume,amount,turn,pctChg",
                start_date=date_str,
                end_date=date_str,
                frequency="d",
                adjustflag="2"
            )
            
            if rs.error_code != '0':
                return None
            
            data_list = []
            while (rs.error_code == '0') & rs.next():
                data_list.append(rs.get_row_data())
            
            if not data_list:
                return None
            
            df = pd.DataFrame(data_list, columns=rs.fields)
            
            # æ•°æ®å¤„ç†
            numeric_cols = ['open', 'close', 'high', 'low', 'volume', 'amount', 'turn', 'pctChg']
            df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors='coerce')
            
            df.rename(columns={
                'date': 'trade_date',
                'open': 'open_price',
                'close': 'close_price',
                'high': 'high_price',
                'low': 'low_price',
                'pctChg': 'change_pct',
                'turn': 'turnover_rate'
            }, inplace=True)
            
            df = df.assign(
                stock_code=stock['code'],
                stock_name=stock['name'],
                change_amount=df['close_price'] - df['close_price'].shift(1),
                amplitude=((df['high_price'] - df['low_price']) / df['close_price'].shift(1) * 100).round(2)
            )
            
            df = df[[
                'stock_code', 'stock_name', 'trade_date',
                'open_price', 'close_price', 'high_price', 'low_price',
                'volume', 'amount', 'change_pct', 'change_amount',
                'turnover_rate', 'amplitude'
            ]]
            
            df = df.replace([np.inf, -np.inf], np.nan)
            df = df.astype(object).where(pd.notnull(df), None)
            
            return df
            
        except Exception as e:
            logger.warning(f"è·å– {stock['code']} å¤±è´¥: {e}")
            return None
    
    def insert_with_copy(self, df: pd.DataFrame) -> tuple:
        """ä½¿ç”¨ COPY æ’å…¥æ•°æ®"""
        start_time = time.time()
        
        try:
            # æ£€æŸ¥è¿æ¥æ˜¯å¦æœ‰æ•ˆï¼Œå¦‚æœæ— æ•ˆåˆ™é‡æ–°è¿æ¥
            try:
                self.conn.isolation_level
            except:
                logger.warning("æ•°æ®åº“è¿æ¥å·²æ–­å¼€ï¼Œæ­£åœ¨é‡æ–°è¿æ¥...")
                self._reconnect()
            
            cursor = self.conn.cursor()
            
            # å…ˆåˆ é™¤å¯èƒ½å­˜åœ¨çš„ä¸´æ—¶è¡¨ï¼Œç„¶ååˆ›å»ºæ–°çš„
            cursor.execute("DROP TABLE IF EXISTS temp_daily_stock_data")
            
            # åˆ›å»ºä¸´æ—¶è¡¨
            cursor.execute("""
                CREATE TEMP TABLE temp_daily_stock_data (
                    stock_code TEXT,
                    stock_name TEXT,
                    trade_date DATE,
                    open_price NUMERIC,
                    close_price NUMERIC,
                    high_price NUMERIC,
                    low_price NUMERIC,
                    volume BIGINT,
                    amount NUMERIC,
                    change_pct NUMERIC,
                    change_amount NUMERIC,
                    turnover_rate NUMERIC,
                    amplitude NUMERIC
                )
            """)
            
            # å‡†å¤‡ CSV æ•°æ®
            buffer = StringIO()
            df.to_csv(buffer, index=False, header=False, na_rep='\\N', sep='\t')
            buffer.seek(0)
            
            # COPY åˆ°ä¸´æ—¶è¡¨
            cursor.copy_from(
                buffer,
                'temp_daily_stock_data',
                sep='\t',
                null='\\N',
                columns=df.columns.tolist()
            )
            
            # æ’å…¥åˆ°æ­£å¼è¡¨
            cursor.execute("""
                INSERT INTO daily_stock_data (
                    stock_code, stock_name, trade_date,
                    open_price, close_price, high_price, low_price,
                    volume, amount, change_pct, change_amount,
                    turnover_rate, amplitude
                )
                SELECT * FROM temp_daily_stock_data
                ON CONFLICT (stock_code, trade_date) DO NOTHING
            """)
            
            inserted_count = cursor.rowcount
            self.conn.commit()
            cursor.close()
            
            elapsed = time.time() - start_time
            return inserted_count, elapsed
            
        except Exception as e:
            self.conn.rollback()
            logger.error(f"COPY æ’å…¥å¤±è´¥: {e}")
            raise
    
    def test_sync(self, stock_count: Optional[int], date_str: str):
        """æµ‹è¯•åŒæ­¥æ€§èƒ½"""
        logger.info(f"\n{'='*60}")
        if stock_count:
            logger.info(f"å¼€å§‹æµ‹è¯•: {stock_count} åªè‚¡ç¥¨, æ—¥æœŸ: {date_str}")
        else:
            logger.info(f"å¼€å§‹æµ‹è¯•: å…¨é‡Aè‚¡, æ—¥æœŸ: {date_str}")
        logger.info(f"{'='*60}\n")
        
        # è·å–è‚¡ç¥¨åˆ—è¡¨
        stocks = self.get_stocks(stock_count)
        actual_count = len(stocks)
        
        # è·å–æ•°æ®
        logger.info("å¼€å§‹è·å–è‚¡ç¥¨æ•°æ®...")
        fetch_start = time.time()
        
        all_data = []
        success = 0
        failed = 0
        total_inserted = 0
        batch_size = 500  # æ¯500åªè‚¡ç¥¨å…¥åº“ä¸€æ¬¡ï¼ˆä¸ç”Ÿäº§ç¯å¢ƒä¸€è‡´ï¼‰
        
        for idx, stock in enumerate(stocks, 1):
            df = self.fetch_stock_data(stock, date_str)
            if df is not None and not df.empty:
                all_data.append(df)
                success += 1
            else:
                failed += 1
            
            # æ¯500åªæˆ–æœ€åä¸€æ‰¹ï¼Œè¿›è¡Œå…¥åº“
            if len(all_data) >= batch_size or idx == actual_count:
                if all_data:
                    try:
                        combined_df = pd.concat(all_data, ignore_index=True)
                        inserted, _ = self.insert_with_copy(combined_df)
                        total_inserted += inserted
                        logger.info(f"âœ… å·²å…¥åº“ {len(all_data)} åªè‚¡ç¥¨ï¼Œ{inserted} æ¡æ–°è®°å½•ï¼Œç´¯è®¡: {total_inserted}")
                        all_data = []  # æ¸…ç©ºç¼“å­˜
                    except Exception as e:
                        logger.error(f"âŒ æ‰¹é‡å…¥åº“å¤±è´¥: {e}")
            
            # å®æ—¶è¿›åº¦æ˜¾ç¤º
            if idx % 10 == 0 or idx == actual_count:
                elapsed = time.time() - fetch_start
                speed = idx / elapsed if elapsed > 0 else 0
                eta = (actual_count - idx) / speed if speed > 0 else 0
                logger.info(
                    f"è¿›åº¦: {idx}/{actual_count} ({idx*100//actual_count}%), "
                    f"æˆåŠŸ: {success}, å¤±è´¥: {failed}, "
                    f"å·²å…¥åº“: {total_inserted}, "
                    f"é€Ÿåº¦: {speed:.1f}è‚¡/ç§’, "
                    f"é¢„è®¡å‰©ä½™: {eta:.0f}ç§’"
                )
        
        fetch_elapsed = time.time() - fetch_start
        logger.info(f"\næ•°æ®è·å–å®Œæˆ: è€—æ—¶ {fetch_elapsed:.2f} ç§’")
        logger.info(f"æˆåŠŸ: {success}, å¤±è´¥: {failed}")
        logger.info(f"æ€»å…¥åº“: {total_inserted} æ¡è®°å½•")
        
        if success == 0:
            logger.error("æ²¡æœ‰è·å–åˆ°ä»»ä½•æ•°æ®")
            return
        
        # å·²ç»å®æ—¶å…¥åº“ï¼Œä¸éœ€è¦å†æ¬¡å…¥åº“
        inserted = total_inserted
        insert_elapsed = 0
        
        # ç»Ÿè®¡ç»“æœ
        total_elapsed = time.time() - fetch_start
        
        logger.info(f"\n{'='*60}")
        logger.info("ğŸ“Š æ€§èƒ½æµ‹è¯•ç»“æœ")
        logger.info(f"{'='*60}")
        logger.info(f"è‚¡ç¥¨æ•°é‡: {actual_count}")
        logger.info(f"æˆåŠŸè·å–: {success}")
        logger.info(f"æˆåŠŸå…¥åº“: {inserted}")
        logger.info(f"")
        logger.info(f"â±ï¸  è€—æ—¶ç»Ÿè®¡:")
        logger.info(f"  æ•°æ®è·å–: {fetch_elapsed:.2f} ç§’ ({fetch_elapsed/60:.1f} åˆ†é’Ÿ)")
        logger.info(f"  æ•°æ®å…¥åº“: {insert_elapsed:.2f} ç§’")
        logger.info(f"  æ€»è€—æ—¶:   {total_elapsed:.2f} ç§’ ({total_elapsed/60:.1f} åˆ†é’Ÿ)")
        logger.info(f"")
        logger.info(f"ğŸš€ é€Ÿåº¦:")
        logger.info(f"  å¹³å‡: {actual_count / total_elapsed * 60:.1f} è‚¡/åˆ†é’Ÿ")
        if insert_elapsed > 0:
            logger.info(f"  å…¥åº“é€Ÿåº¦: {inserted / insert_elapsed:.0f} æ¡/ç§’")
        else:
            logger.info(f"  å…¥åº“é€Ÿåº¦: å®æ—¶å…¥åº“ï¼ˆè¾¹è·å–è¾¹å…¥åº“ï¼‰")
        logger.info(f"{'='*60}\n")
    
    def close(self):
        """å…³é—­è¿æ¥"""
        self.conn.close()
        bs.logout()


def main():
    from datetime import date, timedelta
    
    # é»˜è®¤ä½¿ç”¨æ˜¨å¤©çš„æ—¥æœŸï¼ˆä»Šå¤©çš„æ•°æ®å¯èƒ½è¿˜æ²¡æœ‰ï¼‰
    yesterday = (date.today() - timedelta(days=1)).strftime('%Y-%m-%d')
    
    parser = argparse.ArgumentParser(description='æµ‹è¯• PostgreSQL COPY æ€§èƒ½')
    parser.add_argument('--stocks', type=int, default=50, help='æµ‹è¯•è‚¡ç¥¨æ•°é‡ï¼ˆé»˜è®¤50ï¼Œ0è¡¨ç¤ºå…¨é‡ï¼‰')
    parser.add_argument('--date', type=str, default=yesterday, help=f'åŒæ­¥æ—¥æœŸï¼ˆé»˜è®¤æ˜¨å¤©: {yesterday}ï¼‰')
    parser.add_argument('--all', action='store_true', help='åŒæ­¥æ‰€æœ‰Aè‚¡ï¼ˆç­‰åŒäº --stocks 0ï¼‰')
    args = parser.parse_args()
    
    try:
        tester = CopySyncTester()
        # å¦‚æœæŒ‡å®š --all æˆ– --stocks 0ï¼Œåˆ™è·å–æ‰€æœ‰è‚¡ç¥¨
        stock_count = None if (args.all or args.stocks == 0) else args.stocks
        tester.test_sync(stock_count, args.date)
        tester.close()
        
    except Exception as e:
        logger.error(f"æµ‹è¯•å¤±è´¥: {e}", exc_info=True)
        sys.exit(1)


if __name__ == '__main__':
    main()
