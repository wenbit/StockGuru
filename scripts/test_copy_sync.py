#!/usr/bin/env python3
"""
æµ‹è¯• PostgreSQL COPY æ–¹æ¡ˆæ€§èƒ½
åŒæ­¥å°‘é‡è‚¡ç¥¨æ•°æ®æ¥éªŒè¯é€Ÿåº¦æå‡

ä½¿ç”¨æ–¹æ³•:
    # æ–¹å¼1: ä½¿ç”¨ DATABASE_URL (æ¨è)
    export DATABASE_URL='postgresql://user:password@host:port/database?sslmode=require'
    python scripts/test_copy_sync.py --stocks 50 --date 2025-10-09
    
    # æ–¹å¼2: ä½¿ç”¨ç‹¬ç«‹ç¯å¢ƒå˜é‡
    export SUPABASE_DB_PASSWORD='your_password'
    python scripts/test_copy_sync.py --stocks 50 --date 2025-10-09
"""

import os
import sys
import logging
import argparse
import time
from datetime import date, datetime, timezone, timedelta
from typing import List, Dict, Optional
from pathlib import Path
import pandas as pd
import numpy as np
import baostock as bs
import psycopg2
from io import StringIO
from dotenv import load_dotenv

# åŒ—äº¬æ—¶åŒº (UTC+8)
BEIJING_TZ = timezone(timedelta(hours=8))

# åŠ è½½.envæ–‡ä»¶
project_root = Path(__file__).parent.parent
load_dotenv(project_root / 'stockguru-web' / 'backend' / '.env')

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s'
)
logger = logging.getLogger(__name__)


class CopySyncTester:
    """COPY æ–¹æ¡ˆæ€§èƒ½æµ‹è¯•å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–"""
        # ä¼˜å…ˆä½¿ç”¨ DATABASE_URL
        database_url = os.getenv('DATABASE_URL') or os.getenv('NEON_DATABASE_URL')
        
        if database_url:
            # ä½¿ç”¨ DATABASE_URL è¿æ¥ï¼Œæ·»åŠ è¿æ¥ä¿æ´»å‚æ•°
            logger.info("ä½¿ç”¨ DATABASE_URL è¿æ¥æ•°æ®åº“")
            self.conn = psycopg2.connect(
                database_url,
                keepalives=1,
                keepalives_idle=30,
                keepalives_interval=10,
                keepalives_count=5,
                connect_timeout=30
            )
            logger.info("æ•°æ®åº“è¿æ¥æˆåŠŸ (DATABASE_URL, keepalive enabled)")
        else:
            # å›é€€åˆ°ç‹¬ç«‹ç¯å¢ƒå˜é‡
            self.db_host = os.getenv('SUPABASE_DB_HOST', 'db.mislyhozlviaedinpnfa.supabase.co')
            self.db_password = os.getenv('SUPABASE_DB_PASSWORD')
            self.db_port = int(os.getenv('SUPABASE_DB_PORT', '6543'))
            
            if not self.db_password:
                raise ValueError(
                    "è¯·è®¾ç½®ç¯å¢ƒå˜é‡: DATABASE_URL æˆ– SUPABASE_DB_PASSWORD\n"
                    "ç¤ºä¾‹: export DATABASE_URL='postgresql://user:password@host:port/database?sslmode=require'"
                )
            
            # è¿æ¥æ•°æ®åº“ï¼Œæ·»åŠ è¿æ¥ä¿æ´»å‚æ•°
            self.conn = psycopg2.connect(
                host=self.db_host,
                port=self.db_port,
                database='postgres',
                user='postgres',
                password=self.db_password,
                sslmode='require',
                keepalives=1,
                keepalives_idle=30,
                keepalives_interval=10,
                keepalives_count=5,
                connect_timeout=30
            )
            logger.info(f"æ•°æ®åº“è¿æ¥æˆåŠŸ (keepalive enabled): {self.db_host}:{self.db_port}")
        
        # ç™»å½• baostock
        bs.login()
        logger.info("baostock ç™»å½•æˆåŠŸ")
        
        # ä¿å­˜è¿æ¥å‚æ•°ä»¥ä¾¿é‡è¿
        self.database_url = database_url
        self.db_params = {
            'host': self.db_host if not database_url else None,
            'port': self.db_port if not database_url else None,
            'database': 'postgres' if not database_url else None,
            'user': 'postgres' if not database_url else None,
            'password': self.db_password if not database_url else None,
            'sslmode': 'require' if not database_url else None
        }
        
        # è®°å½•è¿æ¥æ—¶é—´ï¼Œç”¨äºå®šæœŸé‡è¿
        self.last_reconnect_time = time.time()
        self.reconnect_interval = 300  # æ¯5åˆ†é’Ÿä¸»åŠ¨é‡è¿ä¸€æ¬¡
    
    def _reconnect(self):
        """é‡æ–°è¿æ¥æ•°æ®åº“"""
        try:
            if self.conn and not self.conn.closed:
                self.conn.close()
        except:
            pass
        
        if self.database_url:
            # é‡è¿æ—¶ä¹Ÿä½¿ç”¨ä¿æ´»å‚æ•°
            self.conn = psycopg2.connect(
                self.database_url,
                keepalives=1,
                keepalives_idle=30,
                keepalives_interval=10,
                keepalives_count=5,
                connect_timeout=30
            )
            logger.info("æ•°æ®åº“é‡æ–°è¿æ¥æˆåŠŸ (DATABASE_URL, keepalive enabled)")
        else:
            # æ·»åŠ ä¿æ´»å‚æ•°åˆ°é‡è¿
            params = {k: v for k, v in self.db_params.items() if v is not None}
            params.update({
                'keepalives': 1,
                'keepalives_idle': 30,
                'keepalives_interval': 10,
                'keepalives_count': 5,
                'connect_timeout': 30
            })
            self.conn = psycopg2.connect(**params)
            logger.info(f"æ•°æ®åº“é‡æ–°è¿æ¥æˆåŠŸ (keepalive enabled): {self.db_host}:{self.db_port}")
        
        # æ›´æ–°é‡è¿æ—¶é—´
        self.last_reconnect_time = time.time()
    
    def _check_and_reconnect_if_needed(self):
        """æ£€æŸ¥è¿æ¥æ—¶é•¿ï¼Œå¦‚æœè¶…è¿‡é˜ˆå€¼åˆ™ä¸»åŠ¨é‡è¿"""
        elapsed = time.time() - self.last_reconnect_time
        if elapsed > self.reconnect_interval:
            logger.info(f"âš ï¸  è¿æ¥å·²æŒç»­ {elapsed:.0f} ç§’ï¼Œä¸»åŠ¨é‡è¿ä»¥é¿å…è¶…æ—¶...")
            self._reconnect()
    
    def get_synced_stocks(self, date_str: str) -> set:
        """è·å–æŒ‡å®šæ—¥æœŸå·²åŒæ­¥çš„è‚¡ç¥¨ä»£ç åˆ—è¡¨"""
        try:
            cursor = self.conn.cursor()
            cursor.execute("""
                SELECT DISTINCT stock_code 
                FROM daily_stock_data 
                WHERE trade_date = %s
            """, (date_str,))
            synced_codes = {row[0] for row in cursor.fetchall()}
            cursor.close()
            return synced_codes
        except Exception as e:
            logger.warning(f"æŸ¥è¯¢å·²åŒæ­¥è‚¡ç¥¨å¤±è´¥: {e}")
            return set()
    
    def get_stocks(self, limit: int = None, query_date: str = None) -> List[Dict[str, str]]:
        """è·å–æŒ‡å®šæ•°é‡çš„è‚¡ç¥¨"""
        if limit:
            logger.info(f"è·å–å‰ {limit} åªè‚¡ç¥¨...")
        else:
            logger.info(f"è·å–æ‰€æœ‰Aè‚¡è‚¡ç¥¨...")
        
        # åŠ¨æ€è·å–è‚¡ç¥¨åˆ—è¡¨ï¼ˆè‡ªåŠ¨åŒ…å«æ–°è‚¡ã€æ’é™¤é€€å¸‚è‚¡ï¼‰
        # ä½¿ç”¨æŒ‡å®šæ—¥æœŸæˆ–å½“å‰æ—¥æœŸ
        from datetime import date
        if query_date:
            query_day = query_date
        else:
            query_day = date.today().strftime('%Y-%m-%d')
        rs = bs.query_all_stock(day=query_day)
        logger.info(f"æŸ¥è¯¢æ—¥æœŸ: {query_day}")
        
        stocks = []
        while (rs.error_code == '0') & rs.next():
            row = rs.get_row_data()
            # fields: ['code', 'tradeStatus', 'code_name']
            # row[0] = code (å¦‚ 'sh.600000')
            # row[1] = tradeStatus
            # row[2] = code_name
            
            code = row[0]
            name = row[2]
            
            # åªè·å– Aè‚¡ç¥¨ï¼ˆ6ä½æ•°å­—ä»£ç ï¼‰
            # æ’é™¤æŒ‡æ•°ï¼ˆå¦‚ sh.000001ï¼‰å’Œå…¶ä»–éè‚¡ç¥¨ä»£ç 
            if code and '.' in code:
                stock_code = code.split('.')[1]
                # Aè‚¡ä»£ç è§„åˆ™ï¼š
                # æ²ªå¸‚ä¸»æ¿: 600xxx, 601xxx, 603xxx, 605xxx
                # æ²ªå¸‚ç§‘åˆ›æ¿: 688xxx
                # æ·±å¸‚ä¸»æ¿: 000xxx, 001xxx
                # æ·±å¸‚ä¸­å°æ¿: 002xxx, 003xxx, 004xxx
                # æ·±å¸‚åˆ›ä¸šæ¿: 300xxx, 301xxx
                # åŒ—äº¤æ‰€: 8xxxxx, 43xxxx
                if (stock_code.startswith('600') or stock_code.startswith('601') or 
                    stock_code.startswith('603') or stock_code.startswith('605') or
                    stock_code.startswith('688') or  # ç§‘åˆ›æ¿
                    stock_code.startswith('000') or stock_code.startswith('001') or
                    stock_code.startswith('002') or stock_code.startswith('003') or stock_code.startswith('004') or
                    stock_code.startswith('300') or stock_code.startswith('301') or  # åˆ›ä¸šæ¿
                    stock_code.startswith('8') or stock_code.startswith('43')):  # åŒ—äº¤æ‰€
                    stocks.append({
                        'code': stock_code,
                        'full_code': code,
                        'name': name
                    })
                    if limit and len(stocks) >= limit:
                        break
        
        logger.info(f"è·å–åˆ° {len(stocks)} åªè‚¡ç¥¨")
        return stocks
    
    def fetch_stock_data(self, stock: Dict, date_str: str) -> Optional[pd.DataFrame]:
        """è·å–å•åªè‚¡ç¥¨æ•°æ®"""
        try:
            rs = bs.query_history_k_data_plus(
                stock['full_code'],
                "date,code,open,high,low,close,volume,amount,turn,pctChg",
                start_date=date_str,
                end_date=date_str,
                frequency="d",
                adjustflag="2"
            )
            
            if rs.error_code != '0':
                return None
            
            data_list = []
            while (rs.error_code == '0') & rs.next():
                data_list.append(rs.get_row_data())
            
            if not data_list:
                return None
            
            df = pd.DataFrame(data_list, columns=rs.fields)
            
            # æ•°æ®å¤„ç†
            numeric_cols = ['open', 'close', 'high', 'low', 'volume', 'amount', 'turn', 'pctChg']
            df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors='coerce')
            
            df.rename(columns={
                'date': 'trade_date',
                'open': 'open_price',
                'close': 'close_price',
                'high': 'high_price',
                'low': 'low_price',
                'pctChg': 'change_pct',
                'turn': 'turnover_rate'
            }, inplace=True)
            
            df = df.assign(
                stock_code=stock['code'],
                stock_name=stock['name'],
                change_amount=df['close_price'] - df['close_price'].shift(1),
                amplitude=((df['high_price'] - df['low_price']) / df['close_price'].shift(1) * 100).round(2)
            )
            
            df = df[[
                'stock_code', 'stock_name', 'trade_date',
                'open_price', 'close_price', 'high_price', 'low_price',
                'volume', 'amount', 'change_pct', 'change_amount',
                'turnover_rate', 'amplitude'
            ]]
            
            df = df.replace([np.inf, -np.inf], np.nan)
            df = df.astype(object).where(pd.notnull(df), None)
            
            return df
            
        except Exception as e:
            logger.warning(f"è·å– {stock['code']} å¤±è´¥: {e}")
            return None
    
    def insert_with_copy(self, df: pd.DataFrame, max_retries: int = 3) -> tuple:
        """ä½¿ç”¨ COPY æ’å…¥æ•°æ®ï¼Œæ”¯æŒé‡è¯•"""
        start_time = time.time()
        
        # ä¸»åŠ¨æ£€æŸ¥å¹¶é‡è¿ï¼ˆé¿å…è¿æ¥è¶…æ—¶ï¼‰
        self._check_and_reconnect_if_needed()
        
        for attempt in range(max_retries):
            try:
                # æ£€æŸ¥è¿æ¥æ˜¯å¦æœ‰æ•ˆï¼Œå¦‚æœæ— æ•ˆåˆ™é‡æ–°è¿æ¥
                try:
                    self.conn.isolation_level
                except:
                    logger.warning(f"æ•°æ®åº“è¿æ¥å·²æ–­å¼€ï¼Œæ­£åœ¨é‡æ–°è¿æ¥... (å°è¯• {attempt + 1}/{max_retries})")
                    self._reconnect()
                
                cursor = self.conn.cursor()
                
                # å…ˆåˆ é™¤å¯èƒ½å­˜åœ¨çš„ä¸´æ—¶è¡¨ï¼Œç„¶ååˆ›å»ºæ–°çš„
                cursor.execute("DROP TABLE IF EXISTS temp_daily_stock_data")
                
                # åˆ›å»ºä¸´æ—¶è¡¨
                cursor.execute("""
                    CREATE TEMP TABLE temp_daily_stock_data (
                        stock_code TEXT,
                        stock_name TEXT,
                        trade_date DATE,
                        open_price NUMERIC,
                        close_price NUMERIC,
                        high_price NUMERIC,
                        low_price NUMERIC,
                        volume BIGINT,
                        amount NUMERIC,
                        change_pct NUMERIC,
                        change_amount NUMERIC,
                        turnover_rate NUMERIC,
                        amplitude NUMERIC
                    )
                """)
                
                # å‡†å¤‡ CSV æ•°æ®
                buffer = StringIO()
                df.to_csv(buffer, index=False, header=False, na_rep='\\N', sep='\t')
                buffer.seek(0)
                
                # COPY åˆ°ä¸´æ—¶è¡¨
                cursor.copy_from(
                    buffer,
                    'temp_daily_stock_data',
                    sep='\t',
                    null='\\N',
                    columns=df.columns.tolist()
                )
                
                # æ’å…¥åˆ°æ­£å¼è¡¨
                cursor.execute("""
                    INSERT INTO daily_stock_data (
                        stock_code, stock_name, trade_date,
                        open_price, close_price, high_price, low_price,
                        volume, amount, change_pct, change_amount,
                        turnover_rate, amplitude
                    )
                    SELECT * FROM temp_daily_stock_data
                    ON CONFLICT (stock_code, trade_date) DO NOTHING
                """)
                
                inserted_count = cursor.rowcount
                self.conn.commit()
                cursor.close()
                
                elapsed = time.time() - start_time
                return inserted_count, elapsed
                
            except Exception as e:
                try:
                    self.conn.rollback()
                except:
                    pass
                
                if attempt < max_retries - 1:
                    logger.warning(f"âŒ æ‰¹é‡å…¥åº“å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {e}")
                    time.sleep(2)  # ç­‰å¾…2ç§’åé‡è¯•
                    continue
                else:
                    logger.error(f"âŒ æ‰¹é‡å…¥åº“å¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°: {e}")
                    raise
        
        # å¦‚æœæ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
        raise Exception("æ‰¹é‡å…¥åº“å¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°")
    
    def update_sync_status(self, sync_date: str, status: str, total_records: int = 0, 
                           success_count: int = 0, failed_count: int = 0, remarks: str = None):
        """æ›´æ–°åŒæ­¥çŠ¶æ€è®°å½•"""
        try:
            cursor = self.conn.cursor()
            
            # æ£€æŸ¥è®°å½•æ˜¯å¦å­˜åœ¨
            cursor.execute(
                "SELECT id FROM daily_sync_status WHERE sync_date = %s",
                (sync_date,)
            )
            existing = cursor.fetchone()
            
            # ä½¿ç”¨åŒ—äº¬æ—¶é—´ï¼ˆè½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼ï¼Œç¡®ä¿æ—¶åŒºä¿¡æ¯è¢«ä¿ç•™ï¼‰
            beijing_now = datetime.now(BEIJING_TZ)
            beijing_now_str = beijing_now.strftime('%Y-%m-%d %H:%M:%S')
            
            if existing:
                # æ›´æ–°ç°æœ‰è®°å½•
                end_time_str = beijing_now_str if status in ('success', 'failed', 'skipped') else None
                cursor.execute("""
                    UPDATE daily_sync_status 
                    SET status = %s,
                        total_records = %s,
                        success_count = %s,
                        failed_count = %s,
                        remarks = %s,
                        end_time = COALESCE(%s::timestamp, end_time),
                        updated_at = %s::timestamp
                    WHERE sync_date = %s
                """, (status, total_records, success_count, failed_count, remarks, end_time_str, beijing_now_str, sync_date))
            else:
                # åˆ›å»ºæ–°è®°å½•ï¼ˆä½¿ç”¨åŒ—äº¬æ—¶é—´ï¼‰
                cursor.execute("""
                    INSERT INTO daily_sync_status (
                        sync_date, status, total_records, success_count, failed_count, 
                        remarks, start_time
                    ) VALUES (%s, %s, %s, %s, %s, %s, %s::timestamp)
                """, (sync_date, status, total_records, success_count, failed_count, remarks, beijing_now_str))
            
            self.conn.commit()
            cursor.close()
            logger.debug(f"å·²æ›´æ–°åŒæ­¥è®°å½•: {sync_date} - {status}")
        except Exception as e:
            logger.error(f"æ›´æ–°åŒæ­¥è®°å½•å¤±è´¥: {e}")
            try:
                self.conn.rollback()
            except:
                pass
    
    def test_sync(self, stock_count: Optional[int], date_str: str):
        """æµ‹è¯•åŒæ­¥æ€§èƒ½"""
        logger.info(f"\n{'='*60}")
        if stock_count:
            logger.info(f"å¼€å§‹æµ‹è¯•: {stock_count} åªè‚¡ç¥¨, æ—¥æœŸ: {date_str}")
        else:
            logger.info(f"å¼€å§‹æµ‹è¯•: å…¨é‡Aè‚¡, æ—¥æœŸ: {date_str}")
        logger.info(f"{'='*60}\n")
        
        # åˆ›å»ºåŒæ­¥è®°å½•ï¼ˆçŠ¶æ€ï¼šsyncingï¼‰
        self.update_sync_status(date_str, 'syncing', remarks='å¼€å§‹åŒæ­¥')
        
        # è·å–è‚¡ç¥¨åˆ—è¡¨ï¼ˆä½¿ç”¨åŒæ­¥æ—¥æœŸæ¥è·å–å½“æ—¶çš„è‚¡ç¥¨åˆ—è¡¨ï¼‰
        stocks = self.get_stocks(stock_count, query_date=date_str)
        actual_count = len(stocks)
        
        # åˆ¤æ–­æ˜¯å¦ä¸ºéäº¤æ˜“æ—¥ï¼šå¦‚æœè·å–åˆ°çš„è‚¡ç¥¨æ•°ä¸º0ï¼Œè¯´æ˜æ˜¯éäº¤æ˜“æ—¥
        if actual_count == 0:
            logger.info(f"âš ï¸  {date_str} éäº¤æ˜“æ—¥ï¼ˆè·å–åˆ°0åªè‚¡ç¥¨ï¼‰ï¼Œè·³è¿‡åŒæ­¥")
            # æ›´æ–°åŒæ­¥è®°å½•ï¼ˆçŠ¶æ€ï¼šskippedï¼‰
            self.update_sync_status(date_str, 'skipped', remarks='éäº¤æ˜“æ—¥')
            logger.info("âœ… æ‰€æœ‰è‚¡ç¥¨å·²åŒæ­¥å®Œæˆï¼")
            return
        
        # æŸ¥è¯¢å·²åŒæ­¥çš„è‚¡ç¥¨ï¼ˆæ–­ç‚¹ç»­ä¼ ï¼‰
        synced_stocks = self.get_synced_stocks(date_str)
        if synced_stocks:
            logger.info(f"ğŸ“‹ å‘ç°å·²åŒæ­¥ {len(synced_stocks)} åªè‚¡ç¥¨ï¼Œå°†è·³è¿‡...")
            # è¿‡æ»¤æ‰å·²åŒæ­¥çš„è‚¡ç¥¨
            stocks = [s for s in stocks if s['code'] not in synced_stocks]
            logger.info(f"ğŸ“‹ å‰©ä½™å¾…åŒæ­¥: {len(stocks)} åªè‚¡ç¥¨")
        
        if not stocks:
            logger.info("âœ… æ‰€æœ‰è‚¡ç¥¨å·²åŒæ­¥å®Œæˆï¼")
            return
        
        # è·å–æ•°æ®
        logger.info("å¼€å§‹è·å–è‚¡ç¥¨æ•°æ®...")
        fetch_start = time.time()
        
        all_data = []
        success = 0
        failed = 0
        total_inserted = 0
        batch_size = 500  # æ¯500åªè‚¡ç¥¨å…¥åº“ä¸€æ¬¡ï¼ˆä¸ç”Ÿäº§ç¯å¢ƒä¸€è‡´ï¼‰
        remaining_count = len(stocks)  # å‰©ä½™å¾…åŒæ­¥æ•°é‡
        already_synced = len(synced_stocks)  # å·²åŒæ­¥æ•°é‡
        
        for idx, stock in enumerate(stocks, 1):
            df = self.fetch_stock_data(stock, date_str)
            if df is not None and not df.empty:
                all_data.append(df)
                success += 1
            else:
                failed += 1
            
            # æ¯500åªæˆ–æœ€åä¸€æ‰¹ï¼Œè¿›è¡Œå…¥åº“
            if len(all_data) >= batch_size or idx == remaining_count:
                if all_data:
                    try:
                        combined_df = pd.concat(all_data, ignore_index=True)
                        inserted, _ = self.insert_with_copy(combined_df)
                        total_inserted += inserted
                        logger.info(f"âœ… å·²å…¥åº“ {len(all_data)} åªè‚¡ç¥¨ï¼Œ{inserted} æ¡æ–°è®°å½•ï¼Œç´¯è®¡: {already_synced + total_inserted}")
                        
                        # å®æ—¶æ›´æ–°åŒæ­¥è®°å½•
                        current_inserted = already_synced + total_inserted
                        self.update_sync_status(
                            date_str, 
                            'syncing', 
                            total_records=current_inserted,  # æ€»è®°å½•æ•°ï¼šå½“å‰å·²å…¥åº“çš„æ•°æ®æ¡æ•°
                            success_count=current_inserted,  # æˆåŠŸæ•°ï¼šå½“å‰å·²å…¥åº“çš„æ•°æ®æ¡æ•°
                            failed_count=failed,  # å¤±è´¥æ•°ï¼šå·²å¤±è´¥çš„è‚¡ç¥¨æ•°é‡
                            remarks=f'åŒæ­¥ä¸­: è·å–{success}/{actual_count}åª, å¤±è´¥{failed}åª, å·²å…¥åº“{current_inserted}æ¡'
                        )
                        
                        all_data = []  # æ¸…ç©ºç¼“å­˜
                    except Exception as e:
                        logger.error(f"âŒ æ‰¹é‡å…¥åº“å¤±è´¥: {e}")
            
            # å®æ—¶è¿›åº¦æ˜¾ç¤º
            if idx % 10 == 0 or idx == remaining_count:
                elapsed = time.time() - fetch_start
                speed = idx / elapsed if elapsed > 0 else 0
                eta = (remaining_count - idx) / speed if speed > 0 else 0
                current_total = already_synced + success
                logger.info(
                    f"è¿›åº¦: {current_total}/{actual_count} ({current_total*100//actual_count}%), "
                    f"æˆåŠŸ: {success}, å¤±è´¥: {failed}, "
                    f"å·²å…¥åº“: {already_synced + total_inserted}, "
                    f"é€Ÿåº¦: {speed:.1f}è‚¡/ç§’, "
                    f"é¢„è®¡å‰©ä½™: {eta:.0f}ç§’"
                )
        
        fetch_elapsed = time.time() - fetch_start
        logger.info(f"\næ•°æ®è·å–å®Œæˆ: è€—æ—¶ {fetch_elapsed:.2f} ç§’")
        logger.info(f"æˆåŠŸ: {success}, å¤±è´¥: {failed}")
        logger.info(f"æ€»å…¥åº“: {total_inserted} æ¡è®°å½•")
        
        if success == 0:
            logger.error("æ²¡æœ‰è·å–åˆ°ä»»ä½•æ•°æ®")
            # æ›´æ–°åŒæ­¥è®°å½•ï¼ˆçŠ¶æ€ï¼šfailedï¼‰
            self.update_sync_status(date_str, 'failed', remarks='æ²¡æœ‰è·å–åˆ°ä»»ä½•æ•°æ®')
            return
        
        # å·²ç»å®æ—¶å…¥åº“ï¼Œä¸éœ€è¦å†æ¬¡å…¥åº“
        inserted = total_inserted
        insert_elapsed = 0
        
        # ç»Ÿè®¡ç»“æœ
        total_elapsed = time.time() - fetch_start
        
        # åˆ¤æ–­æœ€ç»ˆçŠ¶æ€ï¼šåªæœ‰å…¨éƒ¨æˆåŠŸæ‰æ ‡è®°ä¸ºsuccessï¼Œæœ‰ä»»ä½•å¤±è´¥å°±æ ‡è®°ä¸ºfailed
        final_status = 'success' if failed == 0 else 'failed'
        final_inserted_count = already_synced + total_inserted  # ç´¯è®¡å…¥åº“æ€»æ•°
        final_remarks = f'åŒæ­¥å®Œæˆ: è·å–{success}åª, å¤±è´¥{failed}åª, å…¥åº“{final_inserted_count}æ¡'
        
        # æ›´æ–°åŒæ­¥è®°å½•
        self.update_sync_status(
            date_str, 
            final_status, 
            total_records=final_inserted_count,  # æ€»è®°å½•æ•°ï¼šå®é™…å…¥åº“çš„æ•°æ®æ¡æ•°
            success_count=final_inserted_count,  # æˆåŠŸæ•°ï¼šå®é™…å…¥åº“çš„æ•°æ®æ¡æ•°
            failed_count=failed,  # å¤±è´¥æ•°ï¼šæœ¬æ¬¡å¤±è´¥çš„è‚¡ç¥¨æ•°é‡
            remarks=final_remarks
        )
        
        logger.info(f"\n{'='*60}")
        logger.info("ğŸ“Š æ€§èƒ½æµ‹è¯•ç»“æœ")
        logger.info(f"{'='*60}")
        logger.info(f"è‚¡ç¥¨æ•°é‡: {actual_count}")
        logger.info(f"æˆåŠŸè·å–: {success}")
        logger.info(f"æˆåŠŸå…¥åº“: {inserted}")
        logger.info(f"")
        logger.info(f"â±ï¸  è€—æ—¶ç»Ÿè®¡:")
        logger.info(f"  æ•°æ®è·å–: {fetch_elapsed:.2f} ç§’ ({fetch_elapsed/60:.1f} åˆ†é’Ÿ)")
        logger.info(f"  æ•°æ®å…¥åº“: {insert_elapsed:.2f} ç§’")
        logger.info(f"  æ€»è€—æ—¶:   {total_elapsed:.2f} ç§’ ({total_elapsed/60:.1f} åˆ†é’Ÿ)")
        logger.info(f"")
        logger.info(f"ğŸš€ é€Ÿåº¦:")
        logger.info(f"  å¹³å‡: {actual_count / total_elapsed * 60:.1f} è‚¡/åˆ†é’Ÿ")
        if insert_elapsed > 0:
            logger.info(f"  å…¥åº“é€Ÿåº¦: {inserted / insert_elapsed:.0f} æ¡/ç§’")
        else:
            logger.info(f"  å…¥åº“é€Ÿåº¦: å®æ—¶å…¥åº“ï¼ˆè¾¹è·å–è¾¹å…¥åº“ï¼‰")
        logger.info(f"{'='*60}\n")
    
    def close(self):
        """å…³é—­è¿æ¥"""
        self.conn.close()
        bs.logout()


def main():
    from datetime import date, timedelta
    
    # é»˜è®¤ä½¿ç”¨æ˜¨å¤©çš„æ—¥æœŸï¼ˆä»Šå¤©çš„æ•°æ®å¯èƒ½è¿˜æ²¡æœ‰ï¼‰
    yesterday = (date.today() - timedelta(days=1)).strftime('%Y-%m-%d')
    
    parser = argparse.ArgumentParser(description='æµ‹è¯• PostgreSQL COPY æ€§èƒ½')
    parser.add_argument('--stocks', type=int, default=50, help='æµ‹è¯•è‚¡ç¥¨æ•°é‡ï¼ˆé»˜è®¤50ï¼Œ0è¡¨ç¤ºå…¨é‡ï¼‰')
    parser.add_argument('--date', type=str, default=yesterday, help=f'åŒæ­¥æ—¥æœŸï¼ˆé»˜è®¤æ˜¨å¤©: {yesterday}ï¼‰')
    parser.add_argument('--all', action='store_true', help='åŒæ­¥æ‰€æœ‰Aè‚¡ï¼ˆç­‰åŒäº --stocks 0ï¼‰')
    args = parser.parse_args()
    
    try:
        tester = CopySyncTester()
        # å¦‚æœæŒ‡å®š --all æˆ– --stocks 0ï¼Œåˆ™è·å–æ‰€æœ‰è‚¡ç¥¨
        stock_count = None if (args.all or args.stocks == 0) else args.stocks
        tester.test_sync(stock_count, args.date)
        tester.close()
        
    except Exception as e:
        logger.error(f"æµ‹è¯•å¤±è´¥: {e}", exc_info=True)
        sys.exit(1)


if __name__ == '__main__':
    main()
