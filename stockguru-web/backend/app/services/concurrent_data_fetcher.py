"""
å¹¶å‘æ•°æ®è·å–å™¨
ä½¿ç”¨è¿›ç¨‹æ± å®ç°å¹¶å‘è·å–ï¼ˆBaostock ä¸æ”¯æŒçº¿ç¨‹æ± ï¼‰
é¢„æœŸæé€Ÿ 3-5å€
"""

import logging
import time
from typing import List, Dict, Optional
from concurrent.futures import ProcessPoolExecutor, as_completed
from datetime import date
import pandas as pd

logger = logging.getLogger(__name__)


def _fetch_single_stock(args):
    """
    è·å–å•åªè‚¡ç¥¨æ•°æ®ï¼ˆä¾›è¿›ç¨‹æ± è°ƒç”¨ï¼‰
    æ³¨æ„ï¼šå¿…é¡»æ˜¯é¡¶å±‚å‡½æ•°ï¼Œè¿›ç¨‹æ± æ‰èƒ½åºåˆ—åŒ–
    
    Args:
        args: (stock_code, date_str) å…ƒç»„
    
    Returns:
        åŒ…å«è‚¡ç¥¨ä»£ç å’Œæ•°æ®çš„å­—å…¸
    """
    stock_code, date_str = args
    
    try:
        import baostock as bs
        import pandas as pd
        
        # æ¯ä¸ªè¿›ç¨‹ç‹¬ç«‹ç™»å½•
        bs.login()
        
        try:
            prefix = "sh." if stock_code.startswith('6') else "sz."
            rs = bs.query_history_k_data_plus(
                f"{prefix}{stock_code}",
                "date,code,open,high,low,close,volume,amount,turn,pctChg",
                start_date=date_str,
                end_date=date_str
            )
            
            data = []
            while rs.error_code == '0' and rs.next():
                data.append(rs.get_row_data())
            
            if data:
                df = pd.DataFrame(data, columns=rs.fields)
                return {
                    'code': stock_code,
                    'success': True,
                    'data': df
                }
            else:
                return {
                    'code': stock_code,
                    'success': False,
                    'data': pd.DataFrame()
                }
        
        finally:
            bs.logout()
    
    except Exception as e:
        return {
            'code': stock_code,
            'success': False,
            'data': pd.DataFrame(),
            'error': str(e)
        }


class ConcurrentDataFetcher:
    """
    å¹¶å‘æ•°æ®è·å–å™¨
    ä½¿ç”¨è¿›ç¨‹æ± å¹¶å‘è·å–å¤šåªè‚¡ç¥¨æ•°æ®ï¼ˆBaostock ä¸æ”¯æŒçº¿ç¨‹æ± ï¼‰
    """
    
    def __init__(self, max_workers: int = 5):
        """
        åˆå§‹åŒ–å¹¶å‘è·å–å™¨
        
        Args:
            max_workers: æœ€å¤§å¹¶å‘è¿›ç¨‹æ•°ï¼ˆé»˜è®¤5ï¼Œå»ºè®®3-5ï¼‰
        """
        self.max_workers = max_workers
        logger.info(f"âœ… Concurrent fetcher initialized with {max_workers} processes")
    
    def fetch_single(self, stock_code: str, date_str: str) -> Dict:
        """
        è·å–å•åªè‚¡ç¥¨æ•°æ®ï¼ˆä¾›çº¿ç¨‹æ± è°ƒç”¨ï¼‰
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            date_str: æ—¥æœŸå­—ç¬¦ä¸²
        
        Returns:
            åŒ…å«è‚¡ç¥¨ä»£ç å’Œæ•°æ®çš„å­—å…¸
        """
        try:
            df = self.fetcher.fetch_daily_data(stock_code, date_str)
            return {
                'code': stock_code,
                'success': not df.empty,
                'data': df
            }
        except Exception as e:
            logger.error(f"Failed to fetch {stock_code}: {e}")
            return {
                'code': stock_code,
                'success': False,
                'data': pd.DataFrame(),
                'error': str(e)
            }
    
    def fetch_batch_concurrent(
        self,
        stock_codes: List[str],
        date_str: str,
        progress_callback: Optional[callable] = None
    ) -> List[pd.DataFrame]:
        """
        å¹¶å‘æ‰¹é‡è·å–è‚¡ç¥¨æ•°æ®
        
        Args:
            stock_codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            date_str: æ—¥æœŸå­—ç¬¦ä¸²
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•° callback(current, total, code)
        
        Returns:
            DataFrame åˆ—è¡¨
        """
        results = []
        success_count = 0
        failed_count = 0
        
        logger.info(f"ğŸš€ Starting concurrent fetch for {len(stock_codes)} stocks with {self.max_workers} workers")
        
        start_time = time.time()
        
        # ä½¿ç”¨è¿›ç¨‹æ± å¹¶å‘è·å–
        with ProcessPoolExecutor(max_workers=self.max_workers) as executor:
            # å‡†å¤‡å‚æ•°
            args_list = [(code, date_str) for code in stock_codes]
            
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_code = {
                executor.submit(_fetch_single_stock, args): args[0]
                for args in args_list
            }
            
            # å¤„ç†å®Œæˆçš„ä»»åŠ¡
            for i, future in enumerate(as_completed(future_to_code), 1):
                result = future.result()
                
                if result['success']:
                    results.append(result['data'])
                    success_count += 1
                else:
                    failed_count += 1
                
                # è¿›åº¦å›è°ƒ
                if progress_callback:
                    progress_callback(i, len(stock_codes), result['code'])
                
                # æ¯100åªè¾“å‡ºä¸€æ¬¡è¿›åº¦
                if i % 100 == 0 or i == len(stock_codes):
                    elapsed = time.time() - start_time
                    speed = i / elapsed if elapsed > 0 else 0
                    eta = (len(stock_codes) - i) / speed if speed > 0 else 0
                    logger.info(
                        f"Progress: {i}/{len(stock_codes)} "
                        f"({i/len(stock_codes)*100:.1f}%) "
                        f"Speed: {speed:.1f} stocks/s "
                        f"ETA: {eta:.0f}s"
                    )
        
        elapsed = time.time() - start_time
        
        logger.info(
            f"âœ… Concurrent fetch completed: "
            f"{success_count} success, {failed_count} failed "
            f"in {elapsed:.2f}s ({len(stock_codes)/elapsed:.1f} stocks/s)"
        )
        
        return results
    
    def fetch_and_prepare_for_db(
        self,
        stock_codes: List[str],
        date_str: str,
        progress_callback: Optional[callable] = None
    ) -> List[tuple]:
        """
        å¹¶å‘è·å–æ•°æ®å¹¶å‡†å¤‡æ•°æ®åº“æ’å…¥æ ¼å¼
        
        Args:
            stock_codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            date_str: æ—¥æœŸå­—ç¬¦ä¸²
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
        
        Returns:
            å‡†å¤‡å¥½çš„æ•°æ®åº“æ’å…¥å…ƒç»„åˆ—è¡¨
        """
        logger.info(f"ğŸ”„ Fetching and preparing data for {len(stock_codes)} stocks")
        
        # å¹¶å‘è·å–æ•°æ®
        dataframes = self.fetch_batch_concurrent(stock_codes, date_str, progress_callback)
        
        # å‡†å¤‡æ•°æ®åº“æ’å…¥æ•°æ®
        data_to_insert = []
        
        for df in dataframes:
            if df.empty:
                continue
            
            for _, row in df.iterrows():
                try:
                    # æå–è‚¡ç¥¨ä»£ç 
                    code = row.get('code', '')
                    if '.' in code:
                        code = code.split('.')[1]
                    
                    data_to_insert.append((
                        code,  # stock_code
                        '',  # stock_name (æš‚æ—¶ä¸ºç©º)
                        row.get('date', date_str),  # trade_date
                        float(row.get('open', 0)),  # open_price
                        float(row.get('close', 0)),  # close_price
                        float(row.get('high', 0)),  # high_price
                        float(row.get('low', 0)),  # low_price
                        int(float(row.get('volume', 0))),  # volume
                        float(row.get('amount', 0)),  # amount
                        float(row.get('pctChg', 0)),  # change_pct
                        float(row.get('turn', 0))  # turnover_rate
                    ))
                except Exception as e:
                    logger.warning(f"Failed to prepare data for {code}: {e}")
        
        logger.info(f"âœ… Prepared {len(data_to_insert)} records for database insertion")
        
        return data_to_insert


# å…¨å±€å®ä¾‹ï¼ˆä½¿ç”¨5ä¸ªè¿›ç¨‹ï¼Œå¹³è¡¡æ€§èƒ½å’Œèµ„æºï¼‰
concurrent_fetcher = ConcurrentDataFetcher(max_workers=5)


# ä¾¿æ·å‡½æ•°
def fetch_concurrent(stock_codes: List[str], date_str: str, max_workers: int = 10) -> List[pd.DataFrame]:
    """
    ä¾¿æ·å‡½æ•°ï¼šå¹¶å‘è·å–è‚¡ç¥¨æ•°æ®
    
    Args:
        stock_codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨
        date_str: æ—¥æœŸå­—ç¬¦ä¸²
        max_workers: æœ€å¤§å¹¶å‘æ•°
    
    Returns:
        DataFrame åˆ—è¡¨
    """
    fetcher = ConcurrentDataFetcher(max_workers=max_workers)
    return fetcher.fetch_batch_concurrent(stock_codes, date_str)
