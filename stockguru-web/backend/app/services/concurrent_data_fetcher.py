"""
å¹¶å‘æ•°æ®è·å–å™¨
ä½¿ç”¨çº¿ç¨‹æ± å®ç°å¹¶å‘è·å–ï¼Œé¢„æœŸæé€Ÿ 5-7å€
"""

import logging
import time
from typing import List, Dict, Optional
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import date
import pandas as pd

from app.services.enhanced_data_fetcher import robust_fetcher

logger = logging.getLogger(__name__)


class ConcurrentDataFetcher:
    """
    å¹¶å‘æ•°æ®è·å–å™¨
    ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘è·å–å¤šåªè‚¡ç¥¨æ•°æ®
    """
    
    def __init__(self, max_workers: int = 10):
        """
        åˆå§‹åŒ–å¹¶å‘è·å–å™¨
        
        Args:
            max_workers: æœ€å¤§å¹¶å‘çº¿ç¨‹æ•°ï¼ˆé»˜è®¤10ï¼‰
        """
        self.max_workers = max_workers
        self.fetcher = robust_fetcher
        logger.info(f"âœ… Concurrent fetcher initialized with {max_workers} workers")
    
    def fetch_single(self, stock_code: str, date_str: str) -> Dict:
        """
        è·å–å•åªè‚¡ç¥¨æ•°æ®ï¼ˆä¾›çº¿ç¨‹æ± è°ƒç”¨ï¼‰
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            date_str: æ—¥æœŸå­—ç¬¦ä¸²
        
        Returns:
            åŒ…å«è‚¡ç¥¨ä»£ç å’Œæ•°æ®çš„å­—å…¸
        """
        try:
            df = self.fetcher.fetch_daily_data(stock_code, date_str)
            return {
                'code': stock_code,
                'success': not df.empty,
                'data': df
            }
        except Exception as e:
            logger.error(f"Failed to fetch {stock_code}: {e}")
            return {
                'code': stock_code,
                'success': False,
                'data': pd.DataFrame(),
                'error': str(e)
            }
    
    def fetch_batch_concurrent(
        self,
        stock_codes: List[str],
        date_str: str,
        progress_callback: Optional[callable] = None
    ) -> List[pd.DataFrame]:
        """
        å¹¶å‘æ‰¹é‡è·å–è‚¡ç¥¨æ•°æ®
        
        Args:
            stock_codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            date_str: æ—¥æœŸå­—ç¬¦ä¸²
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•° callback(current, total, code)
        
        Returns:
            DataFrame åˆ—è¡¨
        """
        results = []
        success_count = 0
        failed_count = 0
        
        logger.info(f"ğŸš€ Starting concurrent fetch for {len(stock_codes)} stocks with {self.max_workers} workers")
        
        start_time = time.time()
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘è·å–
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_code = {
                executor.submit(self.fetch_single, code, date_str): code
                for code in stock_codes
            }
            
            # å¤„ç†å®Œæˆçš„ä»»åŠ¡
            for i, future in enumerate(as_completed(future_to_code), 1):
                result = future.result()
                
                if result['success']:
                    results.append(result['data'])
                    success_count += 1
                else:
                    failed_count += 1
                
                # è¿›åº¦å›è°ƒ
                if progress_callback:
                    progress_callback(i, len(stock_codes), result['code'])
                
                # æ¯100åªè¾“å‡ºä¸€æ¬¡è¿›åº¦
                if i % 100 == 0 or i == len(stock_codes):
                    elapsed = time.time() - start_time
                    speed = i / elapsed if elapsed > 0 else 0
                    eta = (len(stock_codes) - i) / speed if speed > 0 else 0
                    logger.info(
                        f"Progress: {i}/{len(stock_codes)} "
                        f"({i/len(stock_codes)*100:.1f}%) "
                        f"Speed: {speed:.1f} stocks/s "
                        f"ETA: {eta:.0f}s"
                    )
        
        elapsed = time.time() - start_time
        
        logger.info(
            f"âœ… Concurrent fetch completed: "
            f"{success_count} success, {failed_count} failed "
            f"in {elapsed:.2f}s ({len(stock_codes)/elapsed:.1f} stocks/s)"
        )
        
        return results
    
    def fetch_and_prepare_for_db(
        self,
        stock_codes: List[str],
        date_str: str,
        progress_callback: Optional[callable] = None
    ) -> List[tuple]:
        """
        å¹¶å‘è·å–æ•°æ®å¹¶å‡†å¤‡æ•°æ®åº“æ’å…¥æ ¼å¼
        
        Args:
            stock_codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            date_str: æ—¥æœŸå­—ç¬¦ä¸²
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
        
        Returns:
            å‡†å¤‡å¥½çš„æ•°æ®åº“æ’å…¥å…ƒç»„åˆ—è¡¨
        """
        logger.info(f"ğŸ”„ Fetching and preparing data for {len(stock_codes)} stocks")
        
        # å¹¶å‘è·å–æ•°æ®
        dataframes = self.fetch_batch_concurrent(stock_codes, date_str, progress_callback)
        
        # å‡†å¤‡æ•°æ®åº“æ’å…¥æ•°æ®
        data_to_insert = []
        
        for df in dataframes:
            if df.empty:
                continue
            
            for _, row in df.iterrows():
                try:
                    # æå–è‚¡ç¥¨ä»£ç 
                    code = row.get('code', '')
                    if '.' in code:
                        code = code.split('.')[1]
                    
                    data_to_insert.append((
                        code,  # stock_code
                        '',  # stock_name (æš‚æ—¶ä¸ºç©º)
                        row.get('date', date_str),  # trade_date
                        float(row.get('open', 0)),  # open_price
                        float(row.get('close', 0)),  # close_price
                        float(row.get('high', 0)),  # high_price
                        float(row.get('low', 0)),  # low_price
                        int(float(row.get('volume', 0))),  # volume
                        float(row.get('amount', 0)),  # amount
                        float(row.get('pctChg', 0)),  # change_pct
                        float(row.get('turn', 0))  # turnover_rate
                    ))
                except Exception as e:
                    logger.warning(f"Failed to prepare data for {code}: {e}")
        
        logger.info(f"âœ… Prepared {len(data_to_insert)} records for database insertion")
        
        return data_to_insert


# å…¨å±€å®ä¾‹
concurrent_fetcher = ConcurrentDataFetcher(max_workers=10)


# ä¾¿æ·å‡½æ•°
def fetch_concurrent(stock_codes: List[str], date_str: str, max_workers: int = 10) -> List[pd.DataFrame]:
    """
    ä¾¿æ·å‡½æ•°ï¼šå¹¶å‘è·å–è‚¡ç¥¨æ•°æ®
    
    Args:
        stock_codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨
        date_str: æ—¥æœŸå­—ç¬¦ä¸²
        max_workers: æœ€å¤§å¹¶å‘æ•°
    
    Returns:
        DataFrame åˆ—è¡¨
    """
    fetcher = ConcurrentDataFetcher(max_workers=max_workers)
    return fetcher.fetch_batch_concurrent(stock_codes, date_str)
