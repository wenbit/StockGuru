# æ•°æ®åŒæ­¥é—®é¢˜ä¿®å¤è®¡åˆ’

## ğŸ¯ æ‰§è¡Œæ­¥éª¤

### ç¬¬ä¸€æ­¥ï¼šåœæ­¢å½“å‰åŒæ­¥ä»»åŠ¡ âœ‹

å½“å‰æœ‰ä¸€ä¸ªæ­£åœ¨è¿è¡Œçš„æ‰¹é‡åŒæ­¥ä»»åŠ¡ï¼ˆ2025-09-08 åˆ° 2025-09-24ï¼‰ï¼Œéœ€è¦å…ˆåœæ­¢ï¼š

```bash
# æ–¹æ³•1ï¼šé‡å¯åç«¯æœåŠ¡
cd /Users/van/dev/source/claudecode_src/StockGuru
./scripts/start/stop-all.sh
# ç­‰å¾…å‡ ç§’
./scripts/start/start-all.sh

# æ–¹æ³•2ï¼šå¦‚æœæœ‰ PID æ–‡ä»¶
kill $(cat logs/.backend.pid)
```

### ç¬¬äºŒæ­¥ï¼šåˆ†æé—®é¢˜æ ¹æº ğŸ”

å·²å®Œæˆåˆ†æï¼Œæ ¸å¿ƒé—®é¢˜ï¼š

1. **è®¡æ•°é€»è¾‘é”™è¯¯**
   - `success_count` åŒ…å«äº†å·²å­˜åœ¨çš„æ•°æ®
   - `failed_count` å¯èƒ½é‡å¤è®¡æ•°
   - `total_records` ä¸å®é™…æ’å…¥æ•°ä¸ç¬¦

2. **09-09 ç¾éš¾æ€§å¤±è´¥**
   - 99.7% å¤±è´¥ç‡ï¼ˆ5354/5372ï¼‰
   - åªæœ‰ 18 æ¡æ•°æ®æˆåŠŸ
   - å¯èƒ½åŸå› ï¼šç½‘ç»œé—®é¢˜ã€baostock é—®é¢˜ã€ä»£ç bug

3. **09-10 éƒ¨åˆ†å¤±è´¥**
   - 41.7% å¤±è´¥ç‡ï¼ˆ2238/5373ï¼‰
   - æ•°æ®é‡ä¸è¶³ï¼ˆ3032 < 4000ï¼‰

### ç¬¬ä¸‰æ­¥ï¼šæ¸…ç†é”™è¯¯æ•°æ® ğŸ§¹

```sql
-- è¿æ¥æ•°æ®åº“
psql $NEON_DATABASE_URL

-- 1. æŸ¥çœ‹å½“å‰çŠ¶æ€
SELECT sync_date, status, total_records, success_count, failed_count
FROM daily_sync_status
WHERE sync_date BETWEEN '2025-09-08' AND '2025-09-11'
ORDER BY sync_date;

-- 2. åˆ é™¤ 09-09 å’Œ 09-10 çš„æ•°æ®ï¼ˆå‡†å¤‡é‡æ–°åŒæ­¥ï¼‰
DELETE FROM daily_stock_data 
WHERE trade_date IN ('2025-09-09', '2025-09-10');

-- 3. é‡ç½®åŒæ­¥çŠ¶æ€
UPDATE daily_sync_status 
SET status = 'pending',
    total_records = 0,
    success_count = 0,
    failed_count = 0,
    start_time = NULL,
    end_time = NULL,
    duration_seconds = NULL,
    remarks = 'å¾…é‡æ–°åŒæ­¥ï¼ˆå·²ä¿®å¤è®¡æ•°é€»è¾‘ï¼‰',
    updated_at = NOW()
WHERE sync_date IN ('2025-09-09', '2025-09-10');

-- 4. éªŒè¯æ¸…ç†ç»“æœ
SELECT trade_date, COUNT(*) 
FROM daily_stock_data 
WHERE trade_date BETWEEN '2025-09-08' AND '2025-09-11'
GROUP BY trade_date;
```

### ç¬¬å››æ­¥ï¼šä¿®å¤ä»£ç  ğŸ”§

#### å…³é”®ä¿®å¤ç‚¹

**1. ä¿®å¤è®¡æ•°é€»è¾‘**

éœ€è¦åŒºåˆ†ï¼š
- `fetch_success`: æˆåŠŸä» baostock è·å–æ•°æ®çš„æ•°é‡
- `fetch_failed`: è·å–å¤±è´¥çš„æ•°é‡  
- `insert_new`: å®é™…æ–°æ’å…¥æ•°æ®åº“çš„æ•°é‡
- `insert_skip`: å·²å­˜åœ¨è·³è¿‡çš„æ•°é‡

**2. æ”¹è¿›é”™è¯¯å¤„ç†**

- æ·»åŠ é‡è¯•æœºåˆ¶ï¼ˆæœ€å¤š 3 æ¬¡ï¼‰
- è¯¦ç»†è®°å½•æ¯ä¸ªå¤±è´¥çš„è‚¡ç¥¨å’ŒåŸå› 
- é¿å…è¿é”å¤±è´¥

**3. æ·»åŠ æ•°æ®éªŒè¯**

- åŒæ­¥åéªŒè¯æ•°æ®é‡
- æ£€æŸ¥å¤±è´¥ç‡
- è‡ªåŠ¨å‘Šè­¦å¼‚å¸¸æƒ…å†µ

#### ä»£ç ä¿®æ”¹å»ºè®®

åˆ›å»ºæ–°çš„åŒæ­¥è„šæœ¬ `scripts/fixed_sync.py`ï¼š

```python
#!/usr/bin/env python3
"""
ä¿®å¤åçš„æ•°æ®åŒæ­¥è„šæœ¬
- å‡†ç¡®çš„è®¡æ•°é€»è¾‘
- å®Œå–„çš„é”™è¯¯å¤„ç†
- è¯¦ç»†çš„æ—¥å¿—è®°å½•
"""

import os
import sys
import time
import logging
import baostock as bs
import psycopg2
from psycopg2.extras import execute_values
from datetime import datetime, timedelta

# é…ç½®æ—¥å¿—
def setup_logging(sync_date):
    log_file = f'logs/sync_{sync_date}.log'
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file),
            logging.StreamHandler()
        ]
    )
    return logging.getLogger(__name__)

class AccurateSyncService:
    """å‡†ç¡®è®¡æ•°çš„åŒæ­¥æœåŠ¡"""
    
    def __init__(self, db_url):
        self.db_url = db_url
        self.conn = None
        self.logger = None
        
    def connect_db(self):
        """è¿æ¥æ•°æ®åº“"""
        self.conn = psycopg2.connect(self.db_url)
        
    def get_all_stocks(self):
        """è·å–æ‰€æœ‰Aè‚¡ä»£ç """
        lg = bs.login()
        rs = bs.query_stock_basic()
        stocks = []
        while rs.next():
            code = rs.get_row_data()[0]
            if code.startswith(('sh.6', 'sz.0', 'sz.3')):
                stocks.append(code)
        bs.logout()
        return stocks
    
    def fetch_stock_data(self, stock_code, sync_date, max_retries=3):
        """è·å–å•åªè‚¡ç¥¨æ•°æ®ï¼ˆå¸¦é‡è¯•ï¼‰"""
        for attempt in range(max_retries):
            try:
                rs = bs.query_history_k_data_plus(
                    stock_code,
                    "date,code,open,high,low,close,preclose,volume,amount,"
                    "adjustflag,turn,tradestatus,pctChg,peTTM,pbMRQ,psTTM,pcfNcfTTM,isST",
                    start_date=sync_date,
                    end_date=sync_date,
                    frequency="d",
                    adjustflag="3"
                )
                
                if rs.error_code == '0':
                    data_list = []
                    while rs.next():
                        data_list.append(rs.get_row_data())
                    return data_list if data_list else None
                else:
                    self.logger.warning(
                        f"{stock_code}: baostock error {rs.error_code} "
                        f"(attempt {attempt+1}/{max_retries})"
                    )
                    
            except Exception as e:
                if attempt < max_retries - 1:
                    time.sleep(0.5)
                    continue
                else:
                    self.logger.error(f"{stock_code}: {str(e)}")
                    return None
        
        return None
    
    def insert_data(self, data_list, sync_date):
        """æ’å…¥æ•°æ®å¹¶è¿”å›å®é™…æ’å…¥çš„æ•°é‡"""
        if not data_list:
            return 0
        
        cur = self.conn.cursor()
        
        # å‡†å¤‡æ•°æ®
        values = []
        for row in data_list:
            # è§£ææ•°æ®
            trade_date = row[0]
            stock_code = row[1].replace('sh.', '').replace('sz.', '')
            
            # è½¬æ¢æ•°å€¼
            def safe_float(val):
                try:
                    return float(val) if val else None
                except:
                    return None
            
            values.append((
                stock_code,
                '',  # stock_name ç¨åæ›´æ–°
                trade_date,
                safe_float(row[2]),  # open
                safe_float(row[4]),  # close
                safe_float(row[3]),  # high
                safe_float(row[4]),  # low
                safe_float(row[6]),  # volume
                safe_float(row[7]),  # amount
                safe_float(row[11]), # change_pct
                None,  # change_amount
                safe_float(row[9]),  # turnover_rate
                None   # amplitude
            ))
        
        # æ’å…¥æ•°æ®
        insert_sql = """
            INSERT INTO daily_stock_data (
                stock_code, stock_name, trade_date,
                open_price, close_price, high_price, low_price,
                volume, amount, change_pct, change_amount,
                turnover_rate, amplitude
            ) VALUES %s
            ON CONFLICT (stock_code, trade_date) DO NOTHING
        """
        
        # æ‰§è¡Œæ’å…¥
        execute_values(cur, insert_sql, values)
        inserted = cur.rowcount
        self.conn.commit()
        
        return inserted
    
    def sync_date(self, sync_date):
        """åŒæ­¥æŒ‡å®šæ—¥æœŸçš„æ•°æ®"""
        self.logger = setup_logging(sync_date)
        self.logger.info(f"=" * 80)
        self.logger.info(f"å¼€å§‹åŒæ­¥ {sync_date}")
        self.logger.info(f"=" * 80)
        
        # è¿æ¥æ•°æ®åº“
        self.connect_db()
        bs.login()
        
        # åˆå§‹åŒ–ç»Ÿè®¡
        stats = {
            'total_stocks': 0,
            'fetch_success': 0,
            'fetch_failed': 0,
            'insert_new': 0,
            'insert_skip': 0,
            'errors': []
        }
        
        # è·å–æ‰€æœ‰è‚¡ç¥¨
        stocks = self.get_all_stocks()
        stats['total_stocks'] = len(stocks)
        self.logger.info(f"æ€»è‚¡ç¥¨æ•°: {stats['total_stocks']}")
        
        # æ›´æ–°åŒæ­¥çŠ¶æ€ä¸º syncing
        self.update_sync_status(
            sync_date, 'syncing', stats['total_stocks'], 0, 0,
            f'å¼€å§‹åŒæ­¥: æ€»è®¡{stats['total_stocks']}åªè‚¡ç¥¨'
        )
        
        start_time = time.time()
        
        # é€ä¸ªåŒæ­¥
        for i, stock in enumerate(stocks, 1):
            try:
                # è·å–æ•°æ®
                data = self.fetch_stock_data(stock, sync_date)
                
                if data is None:
                    stats['fetch_failed'] += 1
                    stats['errors'].append((stock, 'æ— æ•°æ®'))
                    continue
                
                stats['fetch_success'] += 1
                
                # æ’å…¥æ•°æ®
                inserted = self.insert_data(data, sync_date)
                
                if inserted > 0:
                    stats['insert_new'] += inserted
                else:
                    stats['insert_skip'] += 1
                
                # æ¯100åªè‚¡ç¥¨æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
                if i % 100 == 0:
                    progress = i / stats['total_stocks'] * 100
                    elapsed = time.time() - start_time
                    speed = i / elapsed
                    eta = (stats['total_stocks'] - i) / speed if speed > 0 else 0
                    
                    self.logger.info(
                        f"è¿›åº¦: {i}/{stats['total_stocks']} ({progress:.1f}%) | "
                        f"æˆåŠŸ: {stats['fetch_success']} | "
                        f"å¤±è´¥: {stats['fetch_failed']} | "
                        f"é€Ÿåº¦: {speed:.1f}è‚¡/ç§’ | "
                        f"é¢„è®¡å‰©ä½™: {eta/60:.1f}åˆ†é’Ÿ"
                    )
                    
                    # æ›´æ–°åŒæ­¥çŠ¶æ€
                    self.update_sync_status(
                        sync_date, 'syncing', 
                        stats['total_stocks'],
                        stats['insert_new'],
                        stats['fetch_failed'],
                        f"åŒæ­¥ä¸­: {i}/{stats['total_stocks']}, "
                        f"æˆåŠŸ{stats['insert_new']}, å¤±è´¥{stats['fetch_failed']}"
                    )
                
            except Exception as e:
                stats['fetch_failed'] += 1
                stats['errors'].append((stock, str(e)))
                self.logger.error(f"{stock}: {str(e)}")
        
        # åŒæ­¥å®Œæˆ
        duration = time.time() - start_time
        
        # éªŒè¯æ•°æ®
        actual_count = self.get_db_count(sync_date)
        
        # åˆ¤æ–­æœ€ç»ˆçŠ¶æ€
        final_status = 'success' if stats['fetch_failed'] == 0 else 'failed'
        
        # æ›´æ–°æœ€ç»ˆçŠ¶æ€
        self.update_sync_status(
            sync_date,
            final_status,
            stats['total_stocks'],
            stats['insert_new'],  # ä½¿ç”¨å®é™…æ’å…¥æ•°
            stats['fetch_failed'],
            f"åŒæ­¥å®Œæˆ: è·å–æˆåŠŸ{stats['fetch_success']}, å¤±è´¥{stats['fetch_failed']}, "
            f"æ–°æ’å…¥{stats['insert_new']}, å·²å­˜åœ¨{stats['insert_skip']}, "
            f"æ•°æ®åº“å®é™…{actual_count}æ¡, è€—æ—¶{duration/60:.1f}åˆ†é’Ÿ"
        )
        
        # è®°å½•è¯¦ç»†ç»Ÿè®¡
        self.logger.info(f"\n" + "=" * 80)
        self.logger.info(f"åŒæ­¥å®Œæˆç»Ÿè®¡:")
        self.logger.info(f"  æ€»è‚¡ç¥¨æ•°: {stats['total_stocks']}")
        self.logger.info(f"  è·å–æˆåŠŸ: {stats['fetch_success']}")
        self.logger.info(f"  è·å–å¤±è´¥: {stats['fetch_failed']}")
        self.logger.info(f"  æ–°æ’å…¥: {stats['insert_new']}")
        self.logger.info(f"  å·²å­˜åœ¨: {stats['insert_skip']}")
        self.logger.info(f"  æ•°æ®åº“å®é™…: {actual_count}")
        self.logger.info(f"  è€—æ—¶: {duration/60:.1f} åˆ†é’Ÿ")
        self.logger.info(f"=" * 80)
        
        # è®°å½•å¤±è´¥çš„è‚¡ç¥¨
        if stats['errors']:
            self.logger.warning(f"\nå¤±è´¥çš„è‚¡ç¥¨ ({len(stats['errors'])} åª):")
            for stock, error in stats['errors'][:20]:  # åªæ˜¾ç¤ºå‰20ä¸ª
                self.logger.warning(f"  {stock}: {error}")
        
        bs.logout()
        self.conn.close()
        
        return stats
    
    def get_db_count(self, sync_date):
        """è·å–æ•°æ®åº“ä¸­å®é™…çš„è®°å½•æ•°"""
        cur = self.conn.cursor()
        cur.execute(
            "SELECT COUNT(*) FROM daily_stock_data WHERE trade_date = %s",
            (sync_date,)
        )
        return cur.fetchone()[0]
    
    def update_sync_status(self, sync_date, status, total, success, failed, remarks):
        """æ›´æ–°åŒæ­¥çŠ¶æ€"""
        cur = self.conn.cursor()
        
        if status == 'syncing':
            # æ›´æ–°è¿›è¡Œä¸­çš„çŠ¶æ€
            cur.execute("""
                UPDATE daily_sync_status
                SET status = %s,
                    total_records = %s,
                    success_count = %s,
                    failed_count = %s,
                    remarks = %s,
                    updated_at = NOW()
                WHERE sync_date = %s
            """, (status, total, success, failed, remarks, sync_date))
        else:
            # æ›´æ–°æœ€ç»ˆçŠ¶æ€
            cur.execute("""
                UPDATE daily_sync_status
                SET status = %s,
                    total_records = %s,
                    success_count = %s,
                    failed_count = %s,
                    end_time = NOW(),
                    duration_seconds = EXTRACT(EPOCH FROM (NOW() - start_time))::int,
                    remarks = %s,
                    updated_at = NOW()
                WHERE sync_date = %s
            """, (status, total, success, failed, remarks, sync_date))
        
        self.conn.commit()

if __name__ == '__main__':
    import sys
    
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python fixed_sync.py <æ—¥æœŸ>")
        print("ç¤ºä¾‹: python fixed_sync.py 2025-09-09")
        sys.exit(1)
    
    sync_date = sys.argv[1]
    db_url = os.getenv('NEON_DATABASE_URL') or os.getenv('DATABASE_URL')
    
    if not db_url:
        print("é”™è¯¯ï¼šæœªè®¾ç½®æ•°æ®åº“è¿æ¥URL")
        sys.exit(1)
    
    service = AccurateSyncService(db_url)
    stats = service.sync_date(sync_date)
    
    print(f"\nâœ… åŒæ­¥å®Œæˆï¼")
    print(f"   æˆåŠŸ: {stats['insert_new']}")
    print(f"   å¤±è´¥: {stats['fetch_failed']}")
```

### ç¬¬äº”æ­¥ï¼šé‡æ–°åŒæ­¥ ğŸ”„

```bash
# 1. è®¾ç½®ç¯å¢ƒå˜é‡
source stockguru-web/backend/.env

# 2. åŒæ­¥ 09-09
python scripts/fixed_sync.py 2025-09-09

# 3. åŒæ­¥ 09-10
python scripts/fixed_sync.py 2025-09-10

# 4. éªŒè¯ç»“æœ
python scripts/analyze_sync_issue.py
```

### ç¬¬å…­æ­¥ï¼šéªŒè¯ç»“æœ âœ…

```sql
-- 1. æ£€æŸ¥æ•°æ®é‡
SELECT 
    trade_date,
    COUNT(*) as records,
    COUNT(DISTINCT stock_code) as stocks
FROM daily_stock_data
WHERE trade_date BETWEEN '2025-09-08' AND '2025-09-10'
GROUP BY trade_date
ORDER BY trade_date;

-- é¢„æœŸç»“æœï¼š
-- 2025-09-08: ~5200 æ¡
-- 2025-09-09: ~5200 æ¡
-- 2025-09-10: ~5200 æ¡

-- 2. æ£€æŸ¥åŒæ­¥çŠ¶æ€
SELECT 
    sync_date,
    status,
    total_records,
    success_count,
    failed_count,
    remarks
FROM daily_sync_status
WHERE sync_date BETWEEN '2025-09-08' AND '2025-09-10'
ORDER BY sync_date;

-- é¢„æœŸï¼š
-- çŠ¶æ€éƒ½æ˜¯ success
-- success_count ä¸æ•°æ®åº“è®°å½•æ•°ä¸€è‡´
-- failed_count < 100
```

## ğŸ“Š æˆåŠŸæ ‡å‡†

- âœ… æ¯å¤©æ•°æ®é‡ > 4000 æ¡
- âœ… å¤±è´¥ç‡ < 5%
- âœ… success_count ä¸æ•°æ®åº“è®°å½•æ•°ä¸€è‡´ï¼ˆè¯¯å·® < 10ï¼‰
- âœ… æ²¡æœ‰é‡å¤æ•°æ®
- âœ… æ•°æ®è´¨é‡æ­£å¸¸ï¼ˆæ— å¼‚å¸¸ä»·æ ¼ï¼‰

## ğŸš¨ æ³¨æ„äº‹é¡¹

1. **å¤‡ä»½æ•°æ®**ï¼šåœ¨æ¸…ç†å‰å¤‡ä»½é‡è¦æ•°æ®
2. **é€æ­¥æ‰§è¡Œ**ï¼šä¸è¦ä¸€æ¬¡æ€§åŒæ­¥å¤ªå¤šå¤©
3. **ç›‘æ§æ—¥å¿—**ï¼šå¯†åˆ‡å…³æ³¨åŒæ­¥æ—¥å¿—
4. **éªŒè¯ç»“æœ**ï¼šæ¯æ¬¡åŒæ­¥åéƒ½è¦éªŒè¯

## ğŸ“ åç»­æ”¹è¿›

1. **æ·»åŠ è‡ªåŠ¨å‘Šè­¦**ï¼šå¤±è´¥ç‡è¶…è¿‡é˜ˆå€¼æ—¶å‘é€é€šçŸ¥
2. **æ”¹è¿›é‡è¯•ç­–ç•¥**ï¼šæŒ‡æ•°é€€é¿é‡è¯•
3. **ä¼˜åŒ–æ€§èƒ½**ï¼šå¹¶å‘è·å–æ•°æ®
4. **å®Œå–„ç›‘æ§**ï¼šå®æ—¶ç›‘æ§åŒæ­¥å¥åº·åº¦
