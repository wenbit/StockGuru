# 筛选结果差异说明

**问题**: 为什么每次筛选同一天的数据，结果都不一样？

**回答**: 这是正常现象，原因如下：

---

## 🔍 原因分析

### 1. 数据源的实时性

**问文财数据源**:
```python
# 代码位置: stockguru-web/backend/app/services/modules/data_fetcher.py

def get_volume_top_stocks(self, date: str, top_n: int = 100):
    query = f'{date}成交额前{top_n}'
    df = pywencai.get(query=query, loop=True)
```

**特点**:
- 📊 **实时数据**: 问文财返回的是实时/准实时数据
- 🔄 **数据更新**: 数据会随着市场变化而更新
- 📈 **排名变化**: Top100的排名可能会调整

### 2. 数据源的不确定性

**成交额Top100**:
- 不同时间查询，排名可能略有不同
- 数据源可能会修正历史数据
- 边界股票（第98-102名）可能会变动

**热度Top100**:
- 热度是动态指标
- 会随着关注度变化
- 更容易产生差异

### 3. 取交集的影响

```python
# 筛选逻辑
成交额Top100 ∩ 热度Top100 = 候选股票池

# 如果两个列表都有变化
成交额: [A, B, C, D, E, ...]  # 第一次
成交额: [A, B, C, F, G, ...]  # 第二次（D和E被F和G替换）

热度: [A, B, D, F, H, ...]    # 第一次
热度: [A, B, E, G, I, ...]    # 第二次（D和F被E和G替换）

# 交集结果就会不同
第一次交集: [A, B, D, F]
第二次交集: [A, B, E, G]
```

---

## 📊 具体示例

### 场景：筛选 2025-10-14 的数据

**第一次筛选**:
```
成交额Top100: 包含 中芯国际(688981)
热度Top100:   包含 中芯国际(688981)
交集:         中芯国际 入选
最终结果:     中芯国际 排名第1
```

**第二次筛选**（几分钟后）:
```
成交额Top100: 包含 中芯国际(688981)
热度Top100:   不包含 中芯国际(688981)  # 热度排名下降到101名
交集:         中芯国际 未入选
最终结果:     其他股票排名第1
```

---

## 🎯 为什么会这样？

### 1. 数据源特性

**问文财 (pywencai)**:
- 提供的是**动态数据**
- 不是历史快照
- 数据会持续更新和修正

### 2. 市场数据的特点

**成交额**:
- 盘后数据可能会调整
- 大宗交易可能延迟计入
- 数据源可能有修正

**热度**:
- 基于实时关注度
- 会随时间变化
- 更不稳定

### 3. 边界效应

**Top100的边界**:
```
排名 98: 股票A  ← 稳定
排名 99: 股票B  ← 边界，可能变动
排名100: 股票C  ← 边界，可能变动
排名101: 股票D  ← 边界，可能变动
排名102: 股票E  ← 边界，可能变动
```

如果B、C、D、E的数值非常接近，排名就容易变化。

---

## 💡 解决方案

### 方案1: 使用缓存（推荐）

**实现思路**:
```python
# 在 screening_service.py 中添加缓存
from functools import lru_cache
from datetime import datetime

@lru_cache(maxsize=100)
def get_cached_screening_data(date: str):
    """缓存当天的筛选数据"""
    return data_fetcher.get_volume_top_stocks(date, 100)
```

**优点**:
- ✅ 同一天多次查询结果一致
- ✅ 减少API调用
- ✅ 提升响应速度

**缺点**:
- ⚠️ 需要手动清除缓存
- ⚠️ 可能不是最新数据

### 方案2: 数据快照

**实现思路**:
```python
# 每天定时保存数据快照
def save_daily_snapshot(date: str):
    """保存每日数据快照到数据库"""
    volume_data = get_volume_top_stocks(date, 100)
    hot_data = get_hot_top_stocks(date, 100)
    
    # 保存到数据库
    save_to_database(date, volume_data, hot_data)

# 查询时使用快照
def get_snapshot_data(date: str):
    """从数据库读取快照"""
    return load_from_database(date)
```

**优点**:
- ✅ 结果完全一致
- ✅ 数据可追溯
- ✅ 不依赖外部API

**缺点**:
- ⚠️ 需要数据库存储
- ⚠️ 需要定时任务
- ⚠️ 实现复杂度高

### 方案3: 扩大筛选范围

**实现思路**:
```python
# 获取Top150，然后取前100
volume_data = get_volume_top_stocks(date, 150)
hot_data = get_hot_top_stocks(date, 150)

# 取交集后，按综合评分排序，取前30
common_stocks = find_common_stocks(volume_data, hot_data)
top_30 = common_stocks.sort_values('score').head(30)
```

**优点**:
- ✅ 减少边界效应
- ✅ 结果更稳定
- ✅ 实现简单

**缺点**:
- ⚠️ API调用量增加
- ⚠️ 处理时间增加

---

## 🔧 推荐实现

### 简单缓存方案

```python
# 在 data_fetcher.py 中添加

import hashlib
from datetime import datetime

class DataFetcher:
    def __init__(self):
        self.cache = {}  # 简单的内存缓存
        
    def get_volume_top_stocks(self, date: str, top_n: int = 100):
        # 生成缓存key
        cache_key = f"volume_{date}_{top_n}"
        
        # 检查缓存
        if cache_key in self.cache:
            self.logger.info(f"使用缓存数据: {cache_key}")
            return self.cache[cache_key]
        
        # 获取数据
        df = self._fetch_volume_data(date, top_n)
        
        # 保存到缓存
        self.cache[cache_key] = df
        
        return df
    
    def clear_cache(self):
        """清除缓存"""
        self.cache.clear()
```

**使用方式**:
```python
# 每天凌晨清除缓存
scheduler.add_job(data_fetcher.clear_cache, 'cron', hour=0)
```

---

## 📝 用户建议

### 对于普通用户

1. **理解差异是正常的**
   - 这不是bug，是数据源特性
   - 差异通常不大（1-3只股票）
   - 核心股票（前5名）相对稳定

2. **选择合适的时间**
   - 盘后1小时数据较稳定
   - 避免盘中查询
   - 次日查询更准确

3. **关注核心股票**
   - 重点看前3-5名
   - 这些股票排名相对稳定
   - 边界股票可忽略

### 对于开发者

1. **实现缓存机制**
   - 同一天的查询使用缓存
   - 定时清除缓存
   - 提供手动刷新选项

2. **数据快照**
   - 每天保存一份数据快照
   - 用于历史回测
   - 确保数据一致性

3. **扩大筛选范围**
   - 获取Top150，取前100
   - 减少边界效应
   - 提高稳定性

---

## ✅ 总结

### 差异原因
1. ✅ **数据源动态性**: 问文财返回实时数据
2. ✅ **市场数据特点**: 成交额和热度会变化
3. ✅ **边界效应**: Top100边界股票易变动

### 是否正常
- ✅ **完全正常**: 这是数据源的特性
- ✅ **差异不大**: 通常只有1-3只股票不同
- ✅ **核心稳定**: 前5名通常不变

### 解决方案
- 🥇 **推荐**: 实现简单缓存
- 🥈 **备选**: 数据快照
- 🥉 **简单**: 扩大筛选范围

### 用户建议
- 📌 理解这是正常现象
- 📌 关注核心股票（前5名）
- 📌 选择合适的查询时间

---

*最后更新: 2025-10-15 04:36*
